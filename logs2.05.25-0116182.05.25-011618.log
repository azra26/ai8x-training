2022-05-25 01:16:18,873 - Log file for this run: C:\dev\max78000\ai8x-training\logs\2022.05.25-011618\2022.05.25-011618.log
2022-05-25 01:16:20,206 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-05-25 01:16:20,207 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
2022-05-25 01:16:20,385 - Dataset sizes:
	training=8211
	validation=912
	test=3491
2022-05-25 01:16:20,386 - Reading compression schedule from: policies/schedule-humannet.yaml
2022-05-25 01:16:20,397 - 

2022-05-25 01:16:20,398 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:17:36,062 - Epoch: [0][   10/   83]    Overall Loss 0.657036    Objective Loss 0.657036                                        LR 0.001000    Time 7.565283    
2022-05-25 01:17:55,907 - Epoch: [0][   20/   83]    Overall Loss 0.586896    Objective Loss 0.586896                                        LR 0.001000    Time 4.771976    
2022-05-25 01:18:15,744 - Epoch: [0][   30/   83]    Overall Loss 0.543895    Objective Loss 0.543895                                        LR 0.001000    Time 3.840739    
2022-05-25 01:18:35,326 - Epoch: [0][   40/   83]    Overall Loss 0.494836    Objective Loss 0.494836                                        LR 0.001000    Time 3.368693    
2022-05-25 01:18:54,921 - Epoch: [0][   50/   83]    Overall Loss 0.453390    Objective Loss 0.453390                                        LR 0.001000    Time 3.085730    
2022-05-25 01:19:15,740 - Epoch: [0][   60/   83]    Overall Loss 0.413528    Objective Loss 0.413528                                        LR 0.001000    Time 2.917391    
2022-05-25 01:19:39,151 - Epoch: [0][   70/   83]    Overall Loss 0.380495    Objective Loss 0.380495                                        LR 0.001000    Time 2.834078    
2022-05-25 01:20:02,675 - Epoch: [0][   80/   83]    Overall Loss 0.347950    Objective Loss 0.347950                                        LR 0.001000    Time 2.772840    
2022-05-25 01:20:07,473 - Epoch: [0][   83/   83]    Overall Loss 0.338100    Objective Loss 0.338100    Top1 97.297297    LR 0.001000    Time 2.729418    
2022-05-25 01:20:08,602 - --- validate (epoch=0)-----------
2022-05-25 01:20:08,602 - 912 samples (100 per mini-batch)
2022-05-25 01:21:25,408 - Epoch: [0][   10/   10]    Loss 0.108487    Top1 96.929825    
2022-05-25 01:21:26,459 - ==> Top1: 96.930    Loss: 0.108

2022-05-25 01:21:26,460 - ==> Confusion:
[[320  14]
 [ 14 564]]

2022-05-25 01:21:26,648 - ==> Best [Top1: 96.930   Sparsity:0.00   Params: 177072 on epoch: 0]
2022-05-25 01:21:26,649 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:21:26,688 - 

2022-05-25 01:21:26,688 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:22:38,389 - Epoch: [1][   10/   83]    Overall Loss 0.078634    Objective Loss 0.078634                                        LR 0.001000    Time 7.170041    
2022-05-25 01:22:59,693 - Epoch: [1][   20/   83]    Overall Loss 0.065445    Objective Loss 0.065445                                        LR 0.001000    Time 4.646190    
2022-05-25 01:23:22,328 - Epoch: [1][   30/   83]    Overall Loss 0.098615    Objective Loss 0.098615                                        LR 0.001000    Time 3.849576    
2022-05-25 01:23:42,450 - Epoch: [1][   40/   83]    Overall Loss 0.122664    Objective Loss 0.122664                                        LR 0.001000    Time 3.388857    
2022-05-25 01:24:02,137 - Epoch: [1][   50/   83]    Overall Loss 0.117846    Objective Loss 0.117846                                        LR 0.001000    Time 3.103565    
2022-05-25 01:24:22,278 - Epoch: [1][   60/   83]    Overall Loss 0.104164    Objective Loss 0.104164                                        LR 0.001000    Time 2.920844    
2022-05-25 01:24:41,956 - Epoch: [1][   70/   83]    Overall Loss 0.093307    Objective Loss 0.093307                                        LR 0.001000    Time 2.783540    
2022-05-25 01:25:01,251 - Epoch: [1][   80/   83]    Overall Loss 0.084575    Objective Loss 0.084575                                        LR 0.001000    Time 2.676012    
2022-05-25 01:25:05,320 - Epoch: [1][   83/   83]    Overall Loss 0.082017    Objective Loss 0.082017    Top1 100.000000    LR 0.001000    Time 2.627563    
2022-05-25 01:25:06,302 - --- validate (epoch=1)-----------
2022-05-25 01:25:06,302 - 912 samples (100 per mini-batch)
2022-05-25 01:25:58,171 - Epoch: [1][   10/   10]    Loss 0.017274    Top1 99.671053    
2022-05-25 01:25:59,053 - ==> Top1: 99.671    Loss: 0.017

2022-05-25 01:25:59,054 - ==> Confusion:
[[331   3]
 [  0 578]]

2022-05-25 01:25:59,172 - ==> Best [Top1: 99.671   Sparsity:0.00   Params: 177072 on epoch: 1]
2022-05-25 01:25:59,173 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:25:59,199 - 

2022-05-25 01:25:59,199 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:27:04,558 - Epoch: [2][   10/   83]    Overall Loss 0.010704    Objective Loss 0.010704                                        LR 0.001000    Time 6.535768    
2022-05-25 01:27:24,878 - Epoch: [2][   20/   83]    Overall Loss 0.011847    Objective Loss 0.011847                                        LR 0.001000    Time 4.280965    
2022-05-25 01:27:45,081 - Epoch: [2][   30/   83]    Overall Loss 0.011411    Objective Loss 0.011411                                        LR 0.001000    Time 3.524932    
2022-05-25 01:28:04,618 - Epoch: [2][   40/   83]    Overall Loss 0.010935    Objective Loss 0.010935                                        LR 0.001000    Time 3.130575    
2022-05-25 01:28:24,525 - Epoch: [2][   50/   83]    Overall Loss 0.010185    Objective Loss 0.010185                                        LR 0.001000    Time 2.901351    
2022-05-25 01:28:43,938 - Epoch: [2][   60/   83]    Overall Loss 0.010781    Objective Loss 0.010781                                        LR 0.001000    Time 2.740262    
2022-05-25 01:29:03,465 - Epoch: [2][   70/   83]    Overall Loss 0.010446    Objective Loss 0.010446                                        LR 0.001000    Time 2.626850    
2022-05-25 01:29:22,675 - Epoch: [2][   80/   83]    Overall Loss 0.009363    Objective Loss 0.009363                                        LR 0.001000    Time 2.537868    
2022-05-25 01:29:26,728 - Epoch: [2][   83/   83]    Overall Loss 0.009083    Objective Loss 0.009083    Top1 100.000000    LR 0.001000    Time 2.494353    
2022-05-25 01:29:27,736 - --- validate (epoch=2)-----------
2022-05-25 01:29:27,736 - 912 samples (100 per mini-batch)
2022-05-25 01:30:20,028 - Epoch: [2][   10/   10]    Loss 0.005474    Top1 99.671053    
2022-05-25 01:30:20,999 - ==> Top1: 99.671    Loss: 0.005

2022-05-25 01:30:21,000 - ==> Confusion:
[[331   3]
 [  0 578]]

2022-05-25 01:30:21,121 - ==> Best [Top1: 99.671   Sparsity:0.00   Params: 177072 on epoch: 2]
2022-05-25 01:30:21,121 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:30:21,156 - 

2022-05-25 01:30:21,156 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:31:25,462 - Epoch: [3][   10/   83]    Overall Loss 0.008094    Objective Loss 0.008094                                        LR 0.001000    Time 6.430166    
2022-05-25 01:31:45,732 - Epoch: [3][   20/   83]    Overall Loss 0.006531    Objective Loss 0.006531                                        LR 0.001000    Time 4.224623    
2022-05-25 01:32:05,211 - Epoch: [3][   30/   83]    Overall Loss 0.006809    Objective Loss 0.006809                                        LR 0.001000    Time 3.463955    
2022-05-25 01:32:24,981 - Epoch: [3][   40/   83]    Overall Loss 0.006687    Objective Loss 0.006687                                        LR 0.001000    Time 3.090512    
2022-05-25 01:32:44,784 - Epoch: [3][   50/   83]    Overall Loss 0.006595    Objective Loss 0.006595                                        LR 0.001000    Time 2.867141    
2022-05-25 01:33:04,564 - Epoch: [3][   60/   83]    Overall Loss 0.011831    Objective Loss 0.011831                                        LR 0.001000    Time 2.718053    
2022-05-25 01:33:24,428 - Epoch: [3][   70/   83]    Overall Loss 0.030653    Objective Loss 0.030653                                        LR 0.001000    Time 2.612775    
2022-05-25 01:33:44,097 - Epoch: [3][   80/   83]    Overall Loss 0.039456    Objective Loss 0.039456                                        LR 0.001000    Time 2.531400    
2022-05-25 01:33:48,157 - Epoch: [3][   83/   83]    Overall Loss 0.038753    Objective Loss 0.038753    Top1 100.000000    LR 0.001000    Time 2.488089    
2022-05-25 01:33:49,166 - --- validate (epoch=3)-----------
2022-05-25 01:33:49,167 - 912 samples (100 per mini-batch)
2022-05-25 01:35:03,029 - Epoch: [3][   10/   10]    Loss 0.026831    Top1 99.342105    
2022-05-25 01:35:03,992 - ==> Top1: 99.342    Loss: 0.027

2022-05-25 01:35:03,993 - ==> Confusion:
[[329   5]
 [  1 577]]

2022-05-25 01:35:04,100 - ==> Best [Top1: 99.671   Sparsity:0.00   Params: 177072 on epoch: 2]
2022-05-25 01:35:04,101 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:35:04,123 - 

2022-05-25 01:35:04,124 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:36:09,095 - Epoch: [4][   10/   83]    Overall Loss 0.023915    Objective Loss 0.023915                                        LR 0.001000    Time 6.496998    
2022-05-25 01:36:30,093 - Epoch: [4][   20/   83]    Overall Loss 0.017156    Objective Loss 0.017156                                        LR 0.001000    Time 4.295203    
2022-05-25 01:36:49,904 - Epoch: [4][   30/   83]    Overall Loss 0.013991    Objective Loss 0.013991                                        LR 0.001000    Time 3.521555    
2022-05-25 01:37:09,839 - Epoch: [4][   40/   83]    Overall Loss 0.011874    Objective Loss 0.011874                                        LR 0.001000    Time 3.137953    
2022-05-25 01:37:29,896 - Epoch: [4][   50/   83]    Overall Loss 0.010315    Objective Loss 0.010315                                        LR 0.001000    Time 2.910381    
2022-05-25 01:37:49,860 - Epoch: [4][   60/   83]    Overall Loss 0.009582    Objective Loss 0.009582                                        LR 0.001000    Time 2.757205    
2022-05-25 01:38:09,695 - Epoch: [4][   70/   83]    Overall Loss 0.009017    Objective Loss 0.009017                                        LR 0.001000    Time 2.645716    
2022-05-25 01:38:33,778 - Epoch: [4][   80/   83]    Overall Loss 0.009026    Objective Loss 0.009026                                        LR 0.001000    Time 2.615327    
2022-05-25 01:38:39,707 - Epoch: [4][   83/   83]    Overall Loss 0.009040    Objective Loss 0.009040    Top1 100.000000    LR 0.001000    Time 2.591173    
2022-05-25 01:38:40,636 - --- validate (epoch=4)-----------
2022-05-25 01:38:40,636 - 912 samples (100 per mini-batch)
2022-05-25 01:39:33,801 - Epoch: [4][   10/   10]    Loss 0.003293    Top1 99.890351    
2022-05-25 01:39:34,734 - ==> Top1: 99.890    Loss: 0.003

2022-05-25 01:39:34,735 - ==> Confusion:
[[333   1]
 [  0 578]]

2022-05-25 01:39:34,853 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 4]
2022-05-25 01:39:34,854 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:39:34,887 - 

2022-05-25 01:39:34,887 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:40:39,305 - Epoch: [5][   10/   83]    Overall Loss 0.008569    Objective Loss 0.008569                                        LR 0.001000    Time 6.441627    
2022-05-25 01:41:00,436 - Epoch: [5][   20/   83]    Overall Loss 0.007864    Objective Loss 0.007864                                        LR 0.001000    Time 4.274157    
2022-05-25 01:41:21,003 - Epoch: [5][   30/   83]    Overall Loss 0.010361    Objective Loss 0.010361                                        LR 0.001000    Time 3.532640    
2022-05-25 01:41:42,770 - Epoch: [5][   40/   83]    Overall Loss 0.010775    Objective Loss 0.010775                                        LR 0.001000    Time 3.191707    
2022-05-25 01:42:02,830 - Epoch: [5][   50/   83]    Overall Loss 0.010259    Objective Loss 0.010259                                        LR 0.001000    Time 2.953319    
2022-05-25 01:42:28,298 - Epoch: [5][   60/   83]    Overall Loss 0.009323    Objective Loss 0.009323                                        LR 0.001000    Time 2.884720    
2022-05-25 01:42:53,437 - Epoch: [5][   70/   83]    Overall Loss 0.008207    Objective Loss 0.008207                                        LR 0.001000    Time 2.830468    
2022-05-25 01:43:18,763 - Epoch: [5][   80/   83]    Overall Loss 0.007457    Objective Loss 0.007457                                        LR 0.001000    Time 2.792196    
2022-05-25 01:43:25,783 - Epoch: [5][   83/   83]    Overall Loss 0.007208    Objective Loss 0.007208    Top1 100.000000    LR 0.001000    Time 2.774507    
2022-05-25 01:43:27,106 - --- validate (epoch=5)-----------
2022-05-25 01:43:27,106 - 912 samples (100 per mini-batch)
2022-05-25 01:44:30,026 - Epoch: [5][   10/   10]    Loss 0.001726    Top1 100.000000    
2022-05-25 01:44:31,007 - ==> Top1: 100.000    Loss: 0.002

2022-05-25 01:44:31,008 - ==> Confusion:
[[334   0]
 [  0 578]]

2022-05-25 01:44:31,126 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 5]
2022-05-25 01:44:31,127 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:44:31,153 - 

2022-05-25 01:44:31,154 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:45:44,533 - Epoch: [6][   10/   83]    Overall Loss 0.003981    Objective Loss 0.003981                                        LR 0.001000    Time 7.337776    
2022-05-25 01:46:11,721 - Epoch: [6][   20/   83]    Overall Loss 0.003039    Objective Loss 0.003039                                        LR 0.001000    Time 5.024361    
2022-05-25 01:46:33,934 - Epoch: [6][   30/   83]    Overall Loss 0.002339    Objective Loss 0.002339                                        LR 0.001000    Time 4.087842    
2022-05-25 01:46:57,425 - Epoch: [6][   40/   83]    Overall Loss 0.002037    Objective Loss 0.002037                                        LR 0.001000    Time 3.650954    
2022-05-25 01:47:21,290 - Epoch: [6][   50/   83]    Overall Loss 0.001826    Objective Loss 0.001826                                        LR 0.001000    Time 3.396508    
2022-05-25 01:47:45,122 - Epoch: [6][   60/   83]    Overall Loss 0.001594    Objective Loss 0.001594                                        LR 0.001000    Time 3.226149    
2022-05-25 01:48:10,529 - Epoch: [6][   70/   83]    Overall Loss 0.001433    Objective Loss 0.001433                                        LR 0.001000    Time 3.127041    
2022-05-25 01:48:36,981 - Epoch: [6][   80/   83]    Overall Loss 0.001313    Objective Loss 0.001313                                        LR 0.001000    Time 3.065619    
2022-05-25 01:48:42,302 - Epoch: [6][   83/   83]    Overall Loss 0.001273    Objective Loss 0.001273    Top1 100.000000    LR 0.001000    Time 3.017837    
2022-05-25 01:48:43,509 - --- validate (epoch=6)-----------
2022-05-25 01:48:43,510 - 912 samples (100 per mini-batch)
2022-05-25 01:50:20,519 - Epoch: [6][   10/   10]    Loss 0.000775    Top1 100.000000    
2022-05-25 01:50:21,632 - ==> Top1: 100.000    Loss: 0.001

2022-05-25 01:50:21,633 - ==> Confusion:
[[334   0]
 [  0 578]]

2022-05-25 01:50:21,877 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 6]
2022-05-25 01:50:21,878 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:50:21,918 - 

2022-05-25 01:50:21,918 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:51:59,838 - Epoch: [7][   10/   83]    Overall Loss 0.001433    Objective Loss 0.001433                                        LR 0.001000    Time 9.791711    
2022-05-25 01:52:28,162 - Epoch: [7][   20/   83]    Overall Loss 0.002046    Objective Loss 0.002046                                        LR 0.001000    Time 6.307776    
2022-05-25 01:53:02,382 - Epoch: [7][   30/   83]    Overall Loss 0.002538    Objective Loss 0.002538                                        LR 0.001000    Time 5.343023    
2022-05-25 01:53:43,304 - Epoch: [7][   40/   83]    Overall Loss 0.002362    Objective Loss 0.002362                                        LR 0.001000    Time 5.027869    
2022-05-25 01:54:14,352 - Epoch: [7][   50/   83]    Overall Loss 0.002292    Objective Loss 0.002292                                        LR 0.001000    Time 4.641084    
2022-05-25 01:54:39,981 - Epoch: [7][   60/   83]    Overall Loss 0.002259    Objective Loss 0.002259                                        LR 0.001000    Time 4.293275    
2022-05-25 01:55:05,369 - Epoch: [7][   70/   83]    Overall Loss 0.001968    Objective Loss 0.001968                                        LR 0.001000    Time 4.041529    
2022-05-25 01:55:29,580 - Epoch: [7][   80/   83]    Overall Loss 0.002334    Objective Loss 0.002334                                        LR 0.001000    Time 3.837864    
2022-05-25 01:55:33,747 - Epoch: [7][   83/   83]    Overall Loss 0.002924    Objective Loss 0.002924    Top1 100.000000    LR 0.001000    Time 3.748739    
2022-05-25 01:55:34,605 - --- validate (epoch=7)-----------
2022-05-25 01:55:34,605 - 912 samples (100 per mini-batch)
2022-05-25 01:56:08,052 - Epoch: [7][   10/   10]    Loss 0.001245    Top1 100.000000    
2022-05-25 01:56:09,511 - ==> Top1: 100.000    Loss: 0.001

2022-05-25 01:56:09,512 - ==> Confusion:
[[334   0]
 [  0 578]]

2022-05-25 01:56:09,648 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 7]
2022-05-25 01:56:09,648 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 01:56:09,712 - 

2022-05-25 01:56:09,714 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 01:57:04,439 - Epoch: [8][   10/   83]    Overall Loss 0.018163    Objective Loss 0.018163                                        LR 0.001000    Time 5.471980    
2022-05-25 01:57:24,762 - Epoch: [8][   20/   83]    Overall Loss 0.016548    Objective Loss 0.016548                                        LR 0.001000    Time 3.749887    
2022-05-25 01:57:43,569 - Epoch: [8][   30/   83]    Overall Loss 0.018541    Objective Loss 0.018541                                        LR 0.001000    Time 3.125070    
2022-05-25 01:58:03,795 - Epoch: [8][   40/   83]    Overall Loss 0.015982    Objective Loss 0.015982                                        LR 0.001000    Time 2.847955    
2022-05-25 01:58:45,274 - Epoch: [8][   50/   83]    Overall Loss 0.013670    Objective Loss 0.013670                                        LR 0.001000    Time 3.106767    
2022-05-25 01:59:31,788 - Epoch: [8][   60/   83]    Overall Loss 0.013288    Objective Loss 0.013288                                        LR 0.001000    Time 3.362917    
2022-05-25 02:00:12,482 - Epoch: [8][   70/   83]    Overall Loss 0.011939    Objective Loss 0.011939                                        LR 0.001000    Time 3.461833    
2022-05-25 02:00:42,245 - Epoch: [8][   80/   83]    Overall Loss 0.010496    Objective Loss 0.010496                                        LR 0.001000    Time 3.400124    
2022-05-25 02:00:47,539 - Epoch: [8][   83/   83]    Overall Loss 0.010160    Objective Loss 0.010160    Top1 100.000000    LR 0.001000    Time 3.340096    
2022-05-25 02:00:48,748 - --- validate (epoch=8)-----------
2022-05-25 02:00:48,749 - 912 samples (100 per mini-batch)
2022-05-25 02:01:21,537 - Epoch: [8][   10/   10]    Loss 0.000741    Top1 100.000000    
2022-05-25 02:01:22,554 - ==> Top1: 100.000    Loss: 0.001

2022-05-25 02:01:22,555 - ==> Confusion:
[[334   0]
 [  0 578]]

2022-05-25 02:01:22,660 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 8]
2022-05-25 02:01:22,660 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 02:01:22,690 - 

2022-05-25 02:01:22,691 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 02:02:21,142 - Epoch: [9][   10/   83]    Overall Loss 0.000393    Objective Loss 0.000393                                        LR 0.001000    Time 5.844861    
2022-05-25 02:02:40,308 - Epoch: [9][   20/   83]    Overall Loss 0.000478    Objective Loss 0.000478                                        LR 0.001000    Time 3.878302    
2022-05-25 02:03:05,899 - Epoch: [9][   30/   83]    Overall Loss 0.000596    Objective Loss 0.000596                                        LR 0.001000    Time 3.436347    
2022-05-25 02:03:31,547 - Epoch: [9][   40/   83]    Overall Loss 0.000483    Objective Loss 0.000483                                        LR 0.001000    Time 3.216666    
2022-05-25 02:03:54,969 - Epoch: [9][   50/   83]    Overall Loss 0.000481    Objective Loss 0.000481                                        LR 0.001000    Time 3.039998    
2022-05-25 02:04:19,197 - Epoch: [9][   60/   83]    Overall Loss 0.000478    Objective Loss 0.000478                                        LR 0.001000    Time 2.936168    
2022-05-25 02:04:47,472 - Epoch: [9][   70/   83]    Overall Loss 0.000446    Objective Loss 0.000446                                        LR 0.001000    Time 2.919191    
2022-05-25 02:05:08,800 - Epoch: [9][   80/   83]    Overall Loss 0.000416    Objective Loss 0.000416                                        LR 0.001000    Time 2.820062    
2022-05-25 02:05:12,742 - Epoch: [9][   83/   83]    Overall Loss 0.000417    Objective Loss 0.000417    Top1 100.000000    LR 0.001000    Time 2.764883    
2022-05-25 02:05:13,634 - --- validate (epoch=9)-----------
2022-05-25 02:05:13,634 - 912 samples (100 per mini-batch)
2022-05-25 02:05:44,815 - Epoch: [9][   10/   10]    Loss 0.000271    Top1 100.000000    
2022-05-25 02:05:45,811 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 02:05:45,812 - ==> Confusion:
[[334   0]
 [  0 578]]

2022-05-25 02:05:45,901 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 9]
2022-05-25 02:05:45,901 - Saving checkpoint to: logs\2022.05.25-011618\checkpoint.pth.tar
2022-05-25 02:05:45,928 - --- test ---------------------
2022-05-25 02:05:45,930 - 3491 samples (100 per mini-batch)
2022-05-25 02:06:23,029 - Test: [   10/   35]    Loss 0.626016    Top1 81.700000    
2022-05-25 02:06:31,981 - Test: [   20/   35]    Loss 0.636201    Top1 81.800000    
2022-05-25 02:06:40,445 - Test: [   30/   35]    Loss 0.609015    Top1 82.833333    
2022-05-25 02:06:43,764 - Test: [   35/   35]    Loss 0.599360    Top1 83.128044    
2022-05-25 02:06:44,727 - ==> Top1: 83.128    Loss: 0.599

2022-05-25 02:06:44,728 - ==> Confusion:
[[1154  589]
 [   0 1748]]

2022-05-25 02:06:44,738 - 
2022-05-25 02:06:44,739 - Log file for this run: C:\dev\max78000\ai8x-training\logs\2022.05.25-011618\2022.05.25-011618.log
