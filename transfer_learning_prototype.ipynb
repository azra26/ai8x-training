{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bf5ca3",
   "metadata": {},
   "source": [
    "# Transfer Learning Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec210ee",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b771e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import distiller.apputils as apputils\n",
    "\n",
    "import ai8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6666d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a106b9",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f48855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Model Parameters\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "# Freezing of Layer\n",
    "def freeze_layer(layer):\n",
    "    layer.op.weight.requires_grad_(False)\n",
    "    layer.op.bias.requires_grad_(False)\n",
    "\n",
    "# Unfreezing of Layer\n",
    "def unfreeze_layer(layer):\n",
    "    layer.op.weight.requires_grad_(True)\n",
    "    layer.op.bias.requires_grad_(True)\n",
    "\n",
    "# Print Model Parameters\n",
    "def print_model_params(model):\n",
    "    print('Layer, Size, Requires Grad:')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, ',', param.size(),',', param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaaed6",
   "metadata": {},
   "source": [
    "## Loading of Model from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f446a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n",
      "Number of Model Params: 348772\n"
     ]
    }
   ],
   "source": [
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "mod = importlib.import_module(\"models.ai85net-nas-cifar\")\n",
    "\n",
    "model = mod.AI85NASCifarNet(num_classes=100, num_channels=3, dimensions=(32, 32), bias=True)\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "\n",
    "model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(\n",
    "            model, \"trained/ai85-cifar100-new.pth.tar\", model_device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8d0e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer, Size, Requires Grad:\n",
      "conv1_1.output_shift , torch.Size([1]) , False\n",
      "conv1_1.weight_bits , torch.Size([1]) , False\n",
      "conv1_1.bias_bits , torch.Size([1]) , False\n",
      "conv1_1.quantize_activation , torch.Size([1]) , False\n",
      "conv1_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_1.shift_quantile , torch.Size([1]) , False\n",
      "conv1_1.op.weight , torch.Size([64, 3, 3, 3]) , True\n",
      "conv1_1.op.bias , torch.Size([64]) , True\n",
      "conv1_2.output_shift , torch.Size([1]) , False\n",
      "conv1_2.weight_bits , torch.Size([1]) , False\n",
      "conv1_2.bias_bits , torch.Size([1]) , False\n",
      "conv1_2.quantize_activation , torch.Size([1]) , False\n",
      "conv1_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_2.shift_quantile , torch.Size([1]) , False\n",
      "conv1_2.op.weight , torch.Size([32, 64, 1, 1]) , True\n",
      "conv1_2.op.bias , torch.Size([32]) , True\n",
      "conv1_3.output_shift , torch.Size([1]) , False\n",
      "conv1_3.weight_bits , torch.Size([1]) , False\n",
      "conv1_3.bias_bits , torch.Size([1]) , False\n",
      "conv1_3.quantize_activation , torch.Size([1]) , False\n",
      "conv1_3.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_3.shift_quantile , torch.Size([1]) , False\n",
      "conv1_3.op.weight , torch.Size([64, 32, 3, 3]) , True\n",
      "conv1_3.op.bias , torch.Size([64]) , True\n",
      "conv2_1.output_shift , torch.Size([1]) , False\n",
      "conv2_1.weight_bits , torch.Size([1]) , False\n",
      "conv2_1.bias_bits , torch.Size([1]) , False\n",
      "conv2_1.quantize_activation , torch.Size([1]) , False\n",
      "conv2_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv2_1.shift_quantile , torch.Size([1]) , False\n",
      "conv2_1.op.weight , torch.Size([32, 64, 3, 3]) , True\n",
      "conv2_1.op.bias , torch.Size([32]) , True\n",
      "conv2_2.output_shift , torch.Size([1]) , False\n",
      "conv2_2.weight_bits , torch.Size([1]) , False\n",
      "conv2_2.bias_bits , torch.Size([1]) , False\n",
      "conv2_2.quantize_activation , torch.Size([1]) , False\n",
      "conv2_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv2_2.shift_quantile , torch.Size([1]) , False\n",
      "conv2_2.op.weight , torch.Size([64, 32, 1, 1]) , True\n",
      "conv2_2.op.bias , torch.Size([64]) , True\n",
      "conv3_1.output_shift , torch.Size([1]) , False\n",
      "conv3_1.weight_bits , torch.Size([1]) , False\n",
      "conv3_1.bias_bits , torch.Size([1]) , False\n",
      "conv3_1.quantize_activation , torch.Size([1]) , False\n",
      "conv3_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv3_1.shift_quantile , torch.Size([1]) , False\n",
      "conv3_1.op.weight , torch.Size([128, 64, 3, 3]) , True\n",
      "conv3_1.op.bias , torch.Size([128]) , True\n",
      "conv3_2.output_shift , torch.Size([1]) , False\n",
      "conv3_2.weight_bits , torch.Size([1]) , False\n",
      "conv3_2.bias_bits , torch.Size([1]) , False\n",
      "conv3_2.quantize_activation , torch.Size([1]) , False\n",
      "conv3_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv3_2.shift_quantile , torch.Size([1]) , False\n",
      "conv3_2.op.weight , torch.Size([128, 128, 1, 1]) , True\n",
      "conv3_2.op.bias , torch.Size([128]) , True\n",
      "conv4_1.output_shift , torch.Size([1]) , False\n",
      "conv4_1.weight_bits , torch.Size([1]) , False\n",
      "conv4_1.bias_bits , torch.Size([1]) , False\n",
      "conv4_1.quantize_activation , torch.Size([1]) , False\n",
      "conv4_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv4_1.shift_quantile , torch.Size([1]) , False\n",
      "conv4_1.op.weight , torch.Size([64, 128, 3, 3]) , True\n",
      "conv4_1.op.bias , torch.Size([64]) , True\n",
      "conv4_2.output_shift , torch.Size([1]) , False\n",
      "conv4_2.weight_bits , torch.Size([1]) , False\n",
      "conv4_2.bias_bits , torch.Size([1]) , False\n",
      "conv4_2.quantize_activation , torch.Size([1]) , False\n",
      "conv4_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv4_2.shift_quantile , torch.Size([1]) , False\n",
      "conv4_2.op.weight , torch.Size([128, 64, 3, 3]) , True\n",
      "conv4_2.op.bias , torch.Size([128]) , True\n",
      "conv5_1.output_shift , torch.Size([1]) , False\n",
      "conv5_1.weight_bits , torch.Size([1]) , False\n",
      "conv5_1.bias_bits , torch.Size([1]) , False\n",
      "conv5_1.quantize_activation , torch.Size([1]) , False\n",
      "conv5_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv5_1.shift_quantile , torch.Size([1]) , False\n",
      "conv5_1.op.weight , torch.Size([128, 128, 1, 1]) , True\n",
      "conv5_1.op.bias , torch.Size([128]) , True\n",
      "fc.output_shift , torch.Size([1]) , False\n",
      "fc.weight_bits , torch.Size([1]) , False\n",
      "fc.bias_bits , torch.Size([1]) , False\n",
      "fc.quantize_activation , torch.Size([1]) , False\n",
      "fc.adjust_output_shift , torch.Size([1]) , False\n",
      "fc.shift_quantile , torch.Size([1]) , False\n",
      "fc.op.weight , torch.Size([100, 512]) , True\n",
      "fc.op.bias , torch.Size([100]) , True\n"
     ]
    }
   ],
   "source": [
    "# Print Original Model Parameters\n",
    "print_model_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f301e",
   "metadata": {},
   "source": [
    "## Freezing of Layers\n",
    "Note: Layers must to be configured must be the same with the model architecture </br>\n",
    "Changes are found in the op.weight and op.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04fce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AI85NASCifarNet(\n",
       "  (conv1_1): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv1_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv1_3): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv2_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv2_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv3_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv3_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv4_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv4_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv5_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (fc): Linear(\n",
       "    (activate): Empty()\n",
       "    (op): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR 100 NAS Model\n",
    "\n",
    "freeze_layer(model.conv1_1)\n",
    "freeze_layer(model.conv1_2)\n",
    "freeze_layer(model.conv1_3)\n",
    "freeze_layer(model.conv2_1)\n",
    "freeze_layer(model.conv2_2)\n",
    "freeze_layer(model.conv3_1)\n",
    "freeze_layer(model.conv3_2)\n",
    "freeze_layer(model.conv4_1)\n",
    "freeze_layer(model.conv4_2)\n",
    "# freeze_layer(model.conv5_1)\n",
    "# freeze_layer(model.fc)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3c0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer, Size, Requires Grad:\n",
      "conv1_1.output_shift , torch.Size([1]) , False\n",
      "conv1_1.weight_bits , torch.Size([1]) , False\n",
      "conv1_1.bias_bits , torch.Size([1]) , False\n",
      "conv1_1.quantize_activation , torch.Size([1]) , False\n",
      "conv1_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_1.shift_quantile , torch.Size([1]) , False\n",
      "conv1_1.op.weight , torch.Size([64, 3, 3, 3]) , False\n",
      "conv1_1.op.bias , torch.Size([64]) , False\n",
      "conv1_2.output_shift , torch.Size([1]) , False\n",
      "conv1_2.weight_bits , torch.Size([1]) , False\n",
      "conv1_2.bias_bits , torch.Size([1]) , False\n",
      "conv1_2.quantize_activation , torch.Size([1]) , False\n",
      "conv1_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_2.shift_quantile , torch.Size([1]) , False\n",
      "conv1_2.op.weight , torch.Size([32, 64, 1, 1]) , False\n",
      "conv1_2.op.bias , torch.Size([32]) , False\n",
      "conv1_3.output_shift , torch.Size([1]) , False\n",
      "conv1_3.weight_bits , torch.Size([1]) , False\n",
      "conv1_3.bias_bits , torch.Size([1]) , False\n",
      "conv1_3.quantize_activation , torch.Size([1]) , False\n",
      "conv1_3.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_3.shift_quantile , torch.Size([1]) , False\n",
      "conv1_3.op.weight , torch.Size([64, 32, 3, 3]) , False\n",
      "conv1_3.op.bias , torch.Size([64]) , False\n",
      "conv2_1.output_shift , torch.Size([1]) , False\n",
      "conv2_1.weight_bits , torch.Size([1]) , False\n",
      "conv2_1.bias_bits , torch.Size([1]) , False\n",
      "conv2_1.quantize_activation , torch.Size([1]) , False\n",
      "conv2_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv2_1.shift_quantile , torch.Size([1]) , False\n",
      "conv2_1.op.weight , torch.Size([32, 64, 3, 3]) , False\n",
      "conv2_1.op.bias , torch.Size([32]) , False\n",
      "conv2_2.output_shift , torch.Size([1]) , False\n",
      "conv2_2.weight_bits , torch.Size([1]) , False\n",
      "conv2_2.bias_bits , torch.Size([1]) , False\n",
      "conv2_2.quantize_activation , torch.Size([1]) , False\n",
      "conv2_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv2_2.shift_quantile , torch.Size([1]) , False\n",
      "conv2_2.op.weight , torch.Size([64, 32, 1, 1]) , False\n",
      "conv2_2.op.bias , torch.Size([64]) , False\n",
      "conv3_1.output_shift , torch.Size([1]) , False\n",
      "conv3_1.weight_bits , torch.Size([1]) , False\n",
      "conv3_1.bias_bits , torch.Size([1]) , False\n",
      "conv3_1.quantize_activation , torch.Size([1]) , False\n",
      "conv3_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv3_1.shift_quantile , torch.Size([1]) , False\n",
      "conv3_1.op.weight , torch.Size([128, 64, 3, 3]) , False\n",
      "conv3_1.op.bias , torch.Size([128]) , False\n",
      "conv3_2.output_shift , torch.Size([1]) , False\n",
      "conv3_2.weight_bits , torch.Size([1]) , False\n",
      "conv3_2.bias_bits , torch.Size([1]) , False\n",
      "conv3_2.quantize_activation , torch.Size([1]) , False\n",
      "conv3_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv3_2.shift_quantile , torch.Size([1]) , False\n",
      "conv3_2.op.weight , torch.Size([128, 128, 1, 1]) , False\n",
      "conv3_2.op.bias , torch.Size([128]) , False\n",
      "conv4_1.output_shift , torch.Size([1]) , False\n",
      "conv4_1.weight_bits , torch.Size([1]) , False\n",
      "conv4_1.bias_bits , torch.Size([1]) , False\n",
      "conv4_1.quantize_activation , torch.Size([1]) , False\n",
      "conv4_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv4_1.shift_quantile , torch.Size([1]) , False\n",
      "conv4_1.op.weight , torch.Size([64, 128, 3, 3]) , False\n",
      "conv4_1.op.bias , torch.Size([64]) , False\n",
      "conv4_2.output_shift , torch.Size([1]) , False\n",
      "conv4_2.weight_bits , torch.Size([1]) , False\n",
      "conv4_2.bias_bits , torch.Size([1]) , False\n",
      "conv4_2.quantize_activation , torch.Size([1]) , False\n",
      "conv4_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv4_2.shift_quantile , torch.Size([1]) , False\n",
      "conv4_2.op.weight , torch.Size([128, 64, 3, 3]) , False\n",
      "conv4_2.op.bias , torch.Size([128]) , False\n",
      "conv5_1.output_shift , torch.Size([1]) , False\n",
      "conv5_1.weight_bits , torch.Size([1]) , False\n",
      "conv5_1.bias_bits , torch.Size([1]) , False\n",
      "conv5_1.quantize_activation , torch.Size([1]) , False\n",
      "conv5_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv5_1.shift_quantile , torch.Size([1]) , False\n",
      "conv5_1.op.weight , torch.Size([128, 128, 1, 1]) , True\n",
      "conv5_1.op.bias , torch.Size([128]) , True\n",
      "fc.output_shift , torch.Size([1]) , False\n",
      "fc.weight_bits , torch.Size([1]) , False\n",
      "fc.bias_bits , torch.Size([1]) , False\n",
      "fc.quantize_activation , torch.Size([1]) , False\n",
      "fc.adjust_output_shift , torch.Size([1]) , False\n",
      "fc.shift_quantile , torch.Size([1]) , False\n",
      "fc.op.weight , torch.Size([100, 512]) , True\n",
      "fc.op.bias , torch.Size([100]) , True\n"
     ]
    }
   ],
   "source": [
    "# Print Modified Model Parameters\n",
    "print_model_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af23134",
   "metadata": {},
   "source": [
    "## Unfreezing of Layers\n",
    "Note: Layers must to be configured must be the same with the model architecture\n",
    "Changes are found in the op.weight and op.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136395dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AI85NASCifarNet(\n",
       "  (conv1_1): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv1_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv1_3): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv2_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv2_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv3_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv3_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv4_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv4_2): FusedConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (conv5_1): FusedMaxPoolConv2dBNReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (fc): Linear(\n",
       "    (activate): Empty()\n",
       "    (op): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR 100 NAS Model\n",
    "\n",
    "unfreeze_layer(model.conv1_1)\n",
    "unfreeze_layer(model.conv1_2)\n",
    "unfreeze_layer(model.conv1_3)\n",
    "unfreeze_layer(model.conv2_1)\n",
    "unfreeze_layer(model.conv2_2)\n",
    "unfreeze_layer(model.conv3_1)\n",
    "unfreeze_layer(model.conv3_2)\n",
    "unfreeze_layer(model.conv4_1)\n",
    "unfreeze_layer(model.conv4_2)\n",
    "# unfreeze_layer(model.conv5_1)\n",
    "# unfreeze_layer(model.fc)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1f2cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer, Size, Requires Grad:\n",
      "conv1_1.output_shift , torch.Size([1]) , False\n",
      "conv1_1.weight_bits , torch.Size([1]) , False\n",
      "conv1_1.bias_bits , torch.Size([1]) , False\n",
      "conv1_1.quantize_activation , torch.Size([1]) , False\n",
      "conv1_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_1.shift_quantile , torch.Size([1]) , False\n",
      "conv1_1.op.weight , torch.Size([64, 3, 3, 3]) , True\n",
      "conv1_1.op.bias , torch.Size([64]) , True\n",
      "conv1_2.output_shift , torch.Size([1]) , False\n",
      "conv1_2.weight_bits , torch.Size([1]) , False\n",
      "conv1_2.bias_bits , torch.Size([1]) , False\n",
      "conv1_2.quantize_activation , torch.Size([1]) , False\n",
      "conv1_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_2.shift_quantile , torch.Size([1]) , False\n",
      "conv1_2.op.weight , torch.Size([32, 64, 1, 1]) , True\n",
      "conv1_2.op.bias , torch.Size([32]) , True\n",
      "conv1_3.output_shift , torch.Size([1]) , False\n",
      "conv1_3.weight_bits , torch.Size([1]) , False\n",
      "conv1_3.bias_bits , torch.Size([1]) , False\n",
      "conv1_3.quantize_activation , torch.Size([1]) , False\n",
      "conv1_3.adjust_output_shift , torch.Size([1]) , False\n",
      "conv1_3.shift_quantile , torch.Size([1]) , False\n",
      "conv1_3.op.weight , torch.Size([64, 32, 3, 3]) , True\n",
      "conv1_3.op.bias , torch.Size([64]) , True\n",
      "conv2_1.output_shift , torch.Size([1]) , False\n",
      "conv2_1.weight_bits , torch.Size([1]) , False\n",
      "conv2_1.bias_bits , torch.Size([1]) , False\n",
      "conv2_1.quantize_activation , torch.Size([1]) , False\n",
      "conv2_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv2_1.shift_quantile , torch.Size([1]) , False\n",
      "conv2_1.op.weight , torch.Size([32, 64, 3, 3]) , True\n",
      "conv2_1.op.bias , torch.Size([32]) , True\n",
      "conv2_2.output_shift , torch.Size([1]) , False\n",
      "conv2_2.weight_bits , torch.Size([1]) , False\n",
      "conv2_2.bias_bits , torch.Size([1]) , False\n",
      "conv2_2.quantize_activation , torch.Size([1]) , False\n",
      "conv2_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv2_2.shift_quantile , torch.Size([1]) , False\n",
      "conv2_2.op.weight , torch.Size([64, 32, 1, 1]) , True\n",
      "conv2_2.op.bias , torch.Size([64]) , True\n",
      "conv3_1.output_shift , torch.Size([1]) , False\n",
      "conv3_1.weight_bits , torch.Size([1]) , False\n",
      "conv3_1.bias_bits , torch.Size([1]) , False\n",
      "conv3_1.quantize_activation , torch.Size([1]) , False\n",
      "conv3_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv3_1.shift_quantile , torch.Size([1]) , False\n",
      "conv3_1.op.weight , torch.Size([128, 64, 3, 3]) , True\n",
      "conv3_1.op.bias , torch.Size([128]) , True\n",
      "conv3_2.output_shift , torch.Size([1]) , False\n",
      "conv3_2.weight_bits , torch.Size([1]) , False\n",
      "conv3_2.bias_bits , torch.Size([1]) , False\n",
      "conv3_2.quantize_activation , torch.Size([1]) , False\n",
      "conv3_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv3_2.shift_quantile , torch.Size([1]) , False\n",
      "conv3_2.op.weight , torch.Size([128, 128, 1, 1]) , True\n",
      "conv3_2.op.bias , torch.Size([128]) , True\n",
      "conv4_1.output_shift , torch.Size([1]) , False\n",
      "conv4_1.weight_bits , torch.Size([1]) , False\n",
      "conv4_1.bias_bits , torch.Size([1]) , False\n",
      "conv4_1.quantize_activation , torch.Size([1]) , False\n",
      "conv4_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv4_1.shift_quantile , torch.Size([1]) , False\n",
      "conv4_1.op.weight , torch.Size([64, 128, 3, 3]) , True\n",
      "conv4_1.op.bias , torch.Size([64]) , True\n",
      "conv4_2.output_shift , torch.Size([1]) , False\n",
      "conv4_2.weight_bits , torch.Size([1]) , False\n",
      "conv4_2.bias_bits , torch.Size([1]) , False\n",
      "conv4_2.quantize_activation , torch.Size([1]) , False\n",
      "conv4_2.adjust_output_shift , torch.Size([1]) , False\n",
      "conv4_2.shift_quantile , torch.Size([1]) , False\n",
      "conv4_2.op.weight , torch.Size([128, 64, 3, 3]) , True\n",
      "conv4_2.op.bias , torch.Size([128]) , True\n",
      "conv5_1.output_shift , torch.Size([1]) , False\n",
      "conv5_1.weight_bits , torch.Size([1]) , False\n",
      "conv5_1.bias_bits , torch.Size([1]) , False\n",
      "conv5_1.quantize_activation , torch.Size([1]) , False\n",
      "conv5_1.adjust_output_shift , torch.Size([1]) , False\n",
      "conv5_1.shift_quantile , torch.Size([1]) , False\n",
      "conv5_1.op.weight , torch.Size([128, 128, 1, 1]) , True\n",
      "conv5_1.op.bias , torch.Size([128]) , True\n",
      "fc.output_shift , torch.Size([1]) , False\n",
      "fc.weight_bits , torch.Size([1]) , False\n",
      "fc.bias_bits , torch.Size([1]) , False\n",
      "fc.quantize_activation , torch.Size([1]) , False\n",
      "fc.adjust_output_shift , torch.Size([1]) , False\n",
      "fc.shift_quantile , torch.Size([1]) , False\n",
      "fc.op.weight , torch.Size([100, 512]) , True\n",
      "fc.op.bias , torch.Size([100]) , True\n"
     ]
    }
   ],
   "source": [
    "# Print Modified Model Parameters\n",
    "print_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ae69d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
