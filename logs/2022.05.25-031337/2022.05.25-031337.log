2022-05-25 03:13:37,445 - Log file for this run: /media/azra/NEON/skynet-panda/ai8x-training/logs/2022.05.25-031337/2022.05.25-031337.log
2022-05-25 03:13:39,937 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-05-25 03:13:39,938 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
2022-05-25 03:13:39,971 - Dataset sizes:
	training=8211
	validation=912
	test=3491
2022-05-25 03:13:39,972 - Reading compression schedule from: policies/schedule-humannet.yaml
2022-05-25 03:13:39,975 - 

2022-05-25 03:13:39,975 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:13:41,224 - Epoch: [0][   10/   83]    Overall Loss 0.642976    Objective Loss 0.642976                                        LR 0.001000    Time 0.124840    
2022-05-25 03:13:41,612 - Epoch: [0][   20/   83]    Overall Loss 0.615495    Objective Loss 0.615495                                        LR 0.001000    Time 0.077352    
2022-05-25 03:13:41,997 - Epoch: [0][   30/   83]    Overall Loss 0.576519    Objective Loss 0.576519                                        LR 0.001000    Time 0.062147    
2022-05-25 03:13:42,350 - Epoch: [0][   40/   83]    Overall Loss 0.535049    Objective Loss 0.535049                                        LR 0.001000    Time 0.054121    
2022-05-25 03:13:42,702 - Epoch: [0][   50/   83]    Overall Loss 0.495280    Objective Loss 0.495280                                        LR 0.001000    Time 0.049084    
2022-05-25 03:13:43,040 - Epoch: [0][   60/   83]    Overall Loss 0.461746    Objective Loss 0.461746                                        LR 0.001000    Time 0.045638    
2022-05-25 03:13:43,383 - Epoch: [0][   70/   83]    Overall Loss 0.424572    Objective Loss 0.424572                                        LR 0.001000    Time 0.043155    
2022-05-25 03:13:43,707 - Epoch: [0][   80/   83]    Overall Loss 0.388367    Objective Loss 0.388367                                        LR 0.001000    Time 0.041176    
2022-05-25 03:13:43,864 - Epoch: [0][   83/   83]    Overall Loss 0.377862    Objective Loss 0.377862    Top1 97.297297    LR 0.001000    Time 0.041040    
2022-05-25 03:13:43,989 - --- validate (epoch=0)-----------
2022-05-25 03:13:43,989 - 912 samples (100 per mini-batch)
2022-05-25 03:13:44,411 - Epoch: [0][   10/   10]    Loss 0.070326    Top1 99.122807    
2022-05-25 03:13:44,482 - ==> Top1: 99.123    Loss: 0.070

2022-05-25 03:13:44,482 - ==> Confusion:
[[331   4]
 [  4 573]]

2022-05-25 03:13:44,538 - ==> Best [Top1: 99.123   Sparsity:0.00   Params: 177072 on epoch: 0]
2022-05-25 03:13:44,538 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:13:44,571 - 

2022-05-25 03:13:44,571 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:13:45,111 - Epoch: [1][   10/   83]    Overall Loss 0.060359    Objective Loss 0.060359                                        LR 0.001000    Time 0.053853    
2022-05-25 03:13:45,480 - Epoch: [1][   20/   83]    Overall Loss 0.075741    Objective Loss 0.075741                                        LR 0.001000    Time 0.042017    
2022-05-25 03:13:45,837 - Epoch: [1][   30/   83]    Overall Loss 0.079994    Objective Loss 0.079994                                        LR 0.001000    Time 0.038266    
2022-05-25 03:13:46,187 - Epoch: [1][   40/   83]    Overall Loss 0.068270    Objective Loss 0.068270                                        LR 0.001000    Time 0.035805    
2022-05-25 03:13:46,529 - Epoch: [1][   50/   83]    Overall Loss 0.057961    Objective Loss 0.057961                                        LR 0.001000    Time 0.034224    
2022-05-25 03:13:46,869 - Epoch: [1][   60/   83]    Overall Loss 0.052022    Objective Loss 0.052022                                        LR 0.001000    Time 0.033240    
2022-05-25 03:13:47,207 - Epoch: [1][   70/   83]    Overall Loss 0.047675    Objective Loss 0.047675                                        LR 0.001000    Time 0.032572    
2022-05-25 03:13:47,548 - Epoch: [1][   80/   83]    Overall Loss 0.043157    Objective Loss 0.043157                                        LR 0.001000    Time 0.032094    
2022-05-25 03:13:47,675 - Epoch: [1][   83/   83]    Overall Loss 0.043309    Objective Loss 0.043309    Top1 98.198198    LR 0.001000    Time 0.031823    
2022-05-25 03:13:47,802 - --- validate (epoch=1)-----------
2022-05-25 03:13:47,802 - 912 samples (100 per mini-batch)
2022-05-25 03:13:48,198 - Epoch: [1][   10/   10]    Loss 0.231715    Top1 91.995614    
2022-05-25 03:13:48,271 - ==> Top1: 91.996    Loss: 0.232

2022-05-25 03:13:48,271 - ==> Confusion:
[[262  73]
 [  0 577]]

2022-05-25 03:13:48,312 - ==> Best [Top1: 99.123   Sparsity:0.00   Params: 177072 on epoch: 0]
2022-05-25 03:13:48,313 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:13:48,332 - 

2022-05-25 03:13:48,333 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:13:48,855 - Epoch: [2][   10/   83]    Overall Loss 0.070972    Objective Loss 0.070972                                        LR 0.001000    Time 0.052101    
2022-05-25 03:13:49,203 - Epoch: [2][   20/   83]    Overall Loss 0.051814    Objective Loss 0.051814                                        LR 0.001000    Time 0.040296    
2022-05-25 03:13:49,537 - Epoch: [2][   30/   83]    Overall Loss 0.038155    Objective Loss 0.038155                                        LR 0.001000    Time 0.036128    
2022-05-25 03:13:49,895 - Epoch: [2][   40/   83]    Overall Loss 0.031045    Objective Loss 0.031045                                        LR 0.001000    Time 0.034388    
2022-05-25 03:13:50,237 - Epoch: [2][   50/   83]    Overall Loss 0.027673    Objective Loss 0.027673                                        LR 0.001000    Time 0.033267    
2022-05-25 03:13:50,575 - Epoch: [2][   60/   83]    Overall Loss 0.024742    Objective Loss 0.024742                                        LR 0.001000    Time 0.032398    
2022-05-25 03:13:50,920 - Epoch: [2][   70/   83]    Overall Loss 0.021698    Objective Loss 0.021698                                        LR 0.001000    Time 0.031847    
2022-05-25 03:13:51,250 - Epoch: [2][   80/   83]    Overall Loss 0.019698    Objective Loss 0.019698                                        LR 0.001000    Time 0.031304    
2022-05-25 03:13:51,372 - Epoch: [2][   83/   83]    Overall Loss 0.019378    Objective Loss 0.019378    Top1 99.099099    LR 0.001000    Time 0.031037    
2022-05-25 03:13:51,488 - --- validate (epoch=2)-----------
2022-05-25 03:13:51,488 - 912 samples (100 per mini-batch)
2022-05-25 03:13:51,873 - Epoch: [2][   10/   10]    Loss 0.007597    Top1 99.561404    
2022-05-25 03:13:51,955 - ==> Top1: 99.561    Loss: 0.008

2022-05-25 03:13:51,955 - ==> Confusion:
[[332   3]
 [  1 576]]

2022-05-25 03:13:51,996 - ==> Best [Top1: 99.561   Sparsity:0.00   Params: 177072 on epoch: 2]
2022-05-25 03:13:51,996 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:13:52,029 - 

2022-05-25 03:13:52,029 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:13:52,551 - Epoch: [3][   10/   83]    Overall Loss 0.002820    Objective Loss 0.002820                                        LR 0.001000    Time 0.052075    
2022-05-25 03:13:52,901 - Epoch: [3][   20/   83]    Overall Loss 0.003618    Objective Loss 0.003618                                        LR 0.001000    Time 0.040366    
2022-05-25 03:13:53,243 - Epoch: [3][   30/   83]    Overall Loss 0.004961    Objective Loss 0.004961                                        LR 0.001000    Time 0.036411    
2022-05-25 03:13:53,586 - Epoch: [3][   40/   83]    Overall Loss 0.005303    Objective Loss 0.005303                                        LR 0.001000    Time 0.034427    
2022-05-25 03:13:53,918 - Epoch: [3][   50/   83]    Overall Loss 0.005343    Objective Loss 0.005343                                        LR 0.001000    Time 0.033056    
2022-05-25 03:13:54,252 - Epoch: [3][   60/   83]    Overall Loss 0.005149    Objective Loss 0.005149                                        LR 0.001000    Time 0.032190    
2022-05-25 03:13:54,601 - Epoch: [3][   70/   83]    Overall Loss 0.004612    Objective Loss 0.004612                                        LR 0.001000    Time 0.031698    
2022-05-25 03:13:54,925 - Epoch: [3][   80/   83]    Overall Loss 0.004764    Objective Loss 0.004764                                        LR 0.001000    Time 0.031135    
2022-05-25 03:13:55,054 - Epoch: [3][   83/   83]    Overall Loss 0.004625    Objective Loss 0.004625    Top1 100.000000    LR 0.001000    Time 0.030929    
2022-05-25 03:13:55,175 - --- validate (epoch=3)-----------
2022-05-25 03:13:55,176 - 912 samples (100 per mini-batch)
2022-05-25 03:13:55,564 - Epoch: [3][   10/   10]    Loss 0.009564    Top1 99.451754    
2022-05-25 03:13:55,636 - ==> Top1: 99.452    Loss: 0.010

2022-05-25 03:13:55,636 - ==> Confusion:
[[331   4]
 [  1 576]]

2022-05-25 03:13:55,680 - ==> Best [Top1: 99.561   Sparsity:0.00   Params: 177072 on epoch: 2]
2022-05-25 03:13:55,680 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:13:55,699 - 

2022-05-25 03:13:55,700 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:13:56,242 - Epoch: [4][   10/   83]    Overall Loss 0.002358    Objective Loss 0.002358                                        LR 0.001000    Time 0.054090    
2022-05-25 03:13:56,589 - Epoch: [4][   20/   83]    Overall Loss 0.002553    Objective Loss 0.002553                                        LR 0.001000    Time 0.041351    
2022-05-25 03:13:56,935 - Epoch: [4][   30/   83]    Overall Loss 0.002850    Objective Loss 0.002850                                        LR 0.001000    Time 0.037353    
2022-05-25 03:13:57,269 - Epoch: [4][   40/   83]    Overall Loss 0.002769    Objective Loss 0.002769                                        LR 0.001000    Time 0.035172    
2022-05-25 03:13:57,616 - Epoch: [4][   50/   83]    Overall Loss 0.002331    Objective Loss 0.002331                                        LR 0.001000    Time 0.033942    
2022-05-25 03:13:57,965 - Epoch: [4][   60/   83]    Overall Loss 0.002564    Objective Loss 0.002564                                        LR 0.001000    Time 0.033122    
2022-05-25 03:13:58,301 - Epoch: [4][   70/   83]    Overall Loss 0.002904    Objective Loss 0.002904                                        LR 0.001000    Time 0.032439    
2022-05-25 03:13:58,631 - Epoch: [4][   80/   83]    Overall Loss 0.002837    Objective Loss 0.002837                                        LR 0.001000    Time 0.031788    
2022-05-25 03:13:58,755 - Epoch: [4][   83/   83]    Overall Loss 0.002752    Objective Loss 0.002752    Top1 100.000000    LR 0.001000    Time 0.031508    
2022-05-25 03:13:58,877 - --- validate (epoch=4)-----------
2022-05-25 03:13:58,877 - 912 samples (100 per mini-batch)
2022-05-25 03:13:59,270 - Epoch: [4][   10/   10]    Loss 0.010640    Top1 99.561404    
2022-05-25 03:13:59,341 - ==> Top1: 99.561    Loss: 0.011

2022-05-25 03:13:59,341 - ==> Confusion:
[[334   1]
 [  3 574]]

2022-05-25 03:13:59,385 - ==> Best [Top1: 99.561   Sparsity:0.00   Params: 177072 on epoch: 4]
2022-05-25 03:13:59,387 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:13:59,429 - 

2022-05-25 03:13:59,429 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:13:59,969 - Epoch: [5][   10/   83]    Overall Loss 0.005832    Objective Loss 0.005832                                        LR 0.001000    Time 0.053851    
2022-05-25 03:14:00,315 - Epoch: [5][   20/   83]    Overall Loss 0.003962    Objective Loss 0.003962                                        LR 0.001000    Time 0.040985    
2022-05-25 03:14:00,656 - Epoch: [5][   30/   83]    Overall Loss 0.005349    Objective Loss 0.005349                                        LR 0.001000    Time 0.036621    
2022-05-25 03:14:00,994 - Epoch: [5][   40/   83]    Overall Loss 0.004754    Objective Loss 0.004754                                        LR 0.001000    Time 0.034460    
2022-05-25 03:14:01,333 - Epoch: [5][   50/   83]    Overall Loss 0.004002    Objective Loss 0.004002                                        LR 0.001000    Time 0.033211    
2022-05-25 03:14:01,671 - Epoch: [5][   60/   83]    Overall Loss 0.004681    Objective Loss 0.004681                                        LR 0.001000    Time 0.032322    
2022-05-25 03:14:02,016 - Epoch: [5][   70/   83]    Overall Loss 0.004813    Objective Loss 0.004813                                        LR 0.001000    Time 0.031733    
2022-05-25 03:14:02,342 - Epoch: [5][   80/   83]    Overall Loss 0.004305    Objective Loss 0.004305                                        LR 0.001000    Time 0.031159    
2022-05-25 03:14:02,474 - Epoch: [5][   83/   83]    Overall Loss 0.004173    Objective Loss 0.004173    Top1 100.000000    LR 0.001000    Time 0.030900    
2022-05-25 03:14:02,573 - --- validate (epoch=5)-----------
2022-05-25 03:14:02,574 - 912 samples (100 per mini-batch)
2022-05-25 03:14:02,973 - Epoch: [5][   10/   10]    Loss 0.003454    Top1 99.890351    
2022-05-25 03:14:03,043 - ==> Top1: 99.890    Loss: 0.003

2022-05-25 03:14:03,043 - ==> Confusion:
[[334   1]
 [  0 577]]

2022-05-25 03:14:03,085 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 5]
2022-05-25 03:14:03,086 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:14:03,116 - 

2022-05-25 03:14:03,117 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:03,652 - Epoch: [6][   10/   83]    Overall Loss 0.001144    Objective Loss 0.001144                                        LR 0.001000    Time 0.053398    
2022-05-25 03:14:04,005 - Epoch: [6][   20/   83]    Overall Loss 0.000716    Objective Loss 0.000716                                        LR 0.001000    Time 0.040831    
2022-05-25 03:14:04,340 - Epoch: [6][   30/   83]    Overall Loss 0.001104    Objective Loss 0.001104                                        LR 0.001000    Time 0.036567    
2022-05-25 03:14:04,682 - Epoch: [6][   40/   83]    Overall Loss 0.001985    Objective Loss 0.001985                                        LR 0.001000    Time 0.034478    
2022-05-25 03:14:05,015 - Epoch: [6][   50/   83]    Overall Loss 0.001671    Objective Loss 0.001671                                        LR 0.001000    Time 0.033199    
2022-05-25 03:14:05,364 - Epoch: [6][   60/   83]    Overall Loss 0.001495    Objective Loss 0.001495                                        LR 0.001000    Time 0.032518    
2022-05-25 03:14:05,698 - Epoch: [6][   70/   83]    Overall Loss 0.001478    Objective Loss 0.001478                                        LR 0.001000    Time 0.031880    
2022-05-25 03:14:06,042 - Epoch: [6][   80/   83]    Overall Loss 0.001638    Objective Loss 0.001638                                        LR 0.001000    Time 0.031405    
2022-05-25 03:14:06,169 - Epoch: [6][   83/   83]    Overall Loss 0.001648    Objective Loss 0.001648    Top1 100.000000    LR 0.001000    Time 0.031188    
2022-05-25 03:14:06,299 - --- validate (epoch=6)-----------
2022-05-25 03:14:06,300 - 912 samples (100 per mini-batch)
2022-05-25 03:14:06,714 - Epoch: [6][   10/   10]    Loss 0.004922    Top1 99.671053    
2022-05-25 03:14:06,787 - ==> Top1: 99.671    Loss: 0.005

2022-05-25 03:14:06,787 - ==> Confusion:
[[332   3]
 [  0 577]]

2022-05-25 03:14:06,828 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 5]
2022-05-25 03:14:06,830 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:14:06,850 - 

2022-05-25 03:14:06,852 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:07,364 - Epoch: [7][   10/   83]    Overall Loss 0.005453    Objective Loss 0.005453                                        LR 0.001000    Time 0.051030    
2022-05-25 03:14:07,731 - Epoch: [7][   20/   83]    Overall Loss 0.003174    Objective Loss 0.003174                                        LR 0.001000    Time 0.040613    
2022-05-25 03:14:08,085 - Epoch: [7][   30/   83]    Overall Loss 0.002240    Objective Loss 0.002240                                        LR 0.001000    Time 0.036642    
2022-05-25 03:14:08,425 - Epoch: [7][   40/   83]    Overall Loss 0.001760    Objective Loss 0.001760                                        LR 0.001000    Time 0.034497    
2022-05-25 03:14:08,764 - Epoch: [7][   50/   83]    Overall Loss 0.001991    Objective Loss 0.001991                                        LR 0.001000    Time 0.033333    
2022-05-25 03:14:09,110 - Epoch: [7][   60/   83]    Overall Loss 0.002868    Objective Loss 0.002868                                        LR 0.001000    Time 0.032574    
2022-05-25 03:14:09,453 - Epoch: [7][   70/   83]    Overall Loss 0.003242    Objective Loss 0.003242                                        LR 0.001000    Time 0.032019    
2022-05-25 03:14:09,790 - Epoch: [7][   80/   83]    Overall Loss 0.002954    Objective Loss 0.002954                                        LR 0.001000    Time 0.031406    
2022-05-25 03:14:09,915 - Epoch: [7][   83/   83]    Overall Loss 0.002860    Objective Loss 0.002860    Top1 100.000000    LR 0.001000    Time 0.031147    
2022-05-25 03:14:10,025 - --- validate (epoch=7)-----------
2022-05-25 03:14:10,025 - 912 samples (100 per mini-batch)
2022-05-25 03:14:10,423 - Epoch: [7][   10/   10]    Loss 0.006647    Top1 99.671053    
2022-05-25 03:14:10,492 - ==> Top1: 99.671    Loss: 0.007

2022-05-25 03:14:10,492 - ==> Confusion:
[[333   2]
 [  1 576]]

2022-05-25 03:14:10,535 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 5]
2022-05-25 03:14:10,537 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:14:10,559 - 

2022-05-25 03:14:10,560 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:11,088 - Epoch: [8][   10/   83]    Overall Loss 0.000848    Objective Loss 0.000848                                        LR 0.001000    Time 0.052556    
2022-05-25 03:14:11,444 - Epoch: [8][   20/   83]    Overall Loss 0.001246    Objective Loss 0.001246                                        LR 0.001000    Time 0.040731    
2022-05-25 03:14:11,783 - Epoch: [8][   30/   83]    Overall Loss 0.001753    Objective Loss 0.001753                                        LR 0.001000    Time 0.036489    
2022-05-25 03:14:12,121 - Epoch: [8][   40/   83]    Overall Loss 0.002272    Objective Loss 0.002272                                        LR 0.001000    Time 0.034458    
2022-05-25 03:14:12,465 - Epoch: [8][   50/   83]    Overall Loss 0.002487    Objective Loss 0.002487                                        LR 0.001000    Time 0.033262    
2022-05-25 03:14:12,811 - Epoch: [8][   60/   83]    Overall Loss 0.002610    Objective Loss 0.002610                                        LR 0.001000    Time 0.032361    
2022-05-25 03:14:13,161 - Epoch: [8][   70/   83]    Overall Loss 0.002503    Objective Loss 0.002503                                        LR 0.001000    Time 0.031817    
2022-05-25 03:14:13,513 - Epoch: [8][   80/   83]    Overall Loss 0.061911    Objective Loss 0.061911                                        LR 0.001000    Time 0.031515    
2022-05-25 03:14:13,637 - Epoch: [8][   83/   83]    Overall Loss 0.088087    Objective Loss 0.088087    Top1 92.792793    LR 0.001000    Time 0.031293    
2022-05-25 03:14:13,769 - --- validate (epoch=8)-----------
2022-05-25 03:14:13,770 - 912 samples (100 per mini-batch)
2022-05-25 03:14:14,161 - Epoch: [8][   10/   10]    Loss 0.741831    Top1 73.903509    
2022-05-25 03:14:14,232 - ==> Top1: 73.904    Loss: 0.742

2022-05-25 03:14:14,232 - ==> Confusion:
[[334   1]
 [237 340]]

2022-05-25 03:14:14,273 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 5]
2022-05-25 03:14:14,274 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:14:14,294 - 

2022-05-25 03:14:14,296 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:14,817 - Epoch: [9][   10/   83]    Overall Loss 0.345014    Objective Loss 0.345014                                        LR 0.001000    Time 0.051964    
2022-05-25 03:14:15,172 - Epoch: [9][   20/   83]    Overall Loss 0.273389    Objective Loss 0.273389                                        LR 0.001000    Time 0.040455    
2022-05-25 03:14:15,510 - Epoch: [9][   30/   83]    Overall Loss 0.214562    Objective Loss 0.214562                                        LR 0.001000    Time 0.036427    
2022-05-25 03:14:15,842 - Epoch: [9][   40/   83]    Overall Loss 0.175190    Objective Loss 0.175190                                        LR 0.001000    Time 0.034317    
2022-05-25 03:14:16,183 - Epoch: [9][   50/   83]    Overall Loss 0.146808    Objective Loss 0.146808                                        LR 0.001000    Time 0.033153    
2022-05-25 03:14:16,537 - Epoch: [9][   60/   83]    Overall Loss 0.124680    Objective Loss 0.124680                                        LR 0.001000    Time 0.032518    
2022-05-25 03:14:16,887 - Epoch: [9][   70/   83]    Overall Loss 0.108399    Objective Loss 0.108399                                        LR 0.001000    Time 0.031928    
2022-05-25 03:14:17,224 - Epoch: [9][   80/   83]    Overall Loss 0.096220    Objective Loss 0.096220                                        LR 0.001000    Time 0.031401    
2022-05-25 03:14:17,348 - Epoch: [9][   83/   83]    Overall Loss 0.093013    Objective Loss 0.093013    Top1 100.000000    LR 0.001000    Time 0.031132    
2022-05-25 03:14:17,476 - --- validate (epoch=9)-----------
2022-05-25 03:14:17,476 - 912 samples (100 per mini-batch)
2022-05-25 03:14:17,878 - Epoch: [9][   10/   10]    Loss 0.022260    Top1 99.232456    
2022-05-25 03:14:17,954 - ==> Top1: 99.232    Loss: 0.022

2022-05-25 03:14:17,955 - ==> Confusion:
[[328   7]
 [  0 577]]

2022-05-25 03:14:17,997 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 5]
2022-05-25 03:14:17,998 - Saving checkpoint to: logs/2022.05.25-031337/checkpoint.pth.tar
2022-05-25 03:14:18,037 - 

2022-05-25 03:14:18,038 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:18,674 - Epoch: [10][   10/   83]    Overall Loss 0.057940    Objective Loss 0.057940                                        LR 0.000500    Time 0.063440    
2022-05-25 03:14:19,112 - Epoch: [10][   20/   83]    Overall Loss 0.099649    Objective Loss 0.099649                                        LR 0.000500    Time 0.050077    
2022-05-25 03:14:19,539 - Epoch: [10][   30/   83]    Overall Loss 0.073981    Objective Loss 0.073981                                        LR 0.000500    Time 0.045508    
2022-05-25 03:14:19,976 - Epoch: [10][   40/   83]    Overall Loss 0.066896    Objective Loss 0.066896                                        LR 0.000500    Time 0.043429    
2022-05-25 03:14:20,398 - Epoch: [10][   50/   83]    Overall Loss 0.060300    Objective Loss 0.060300                                        LR 0.000500    Time 0.042254    
2022-05-25 03:14:20,836 - Epoch: [10][   60/   83]    Overall Loss 0.051156    Objective Loss 0.051156                                        LR 0.000500    Time 0.041527    
2022-05-25 03:14:21,263 - Epoch: [10][   70/   83]    Overall Loss 0.046228    Objective Loss 0.046228                                        LR 0.000500    Time 0.040906    
2022-05-25 03:14:21,679 - Epoch: [10][   80/   83]    Overall Loss 0.040602    Objective Loss 0.040602                                        LR 0.000500    Time 0.040238    
2022-05-25 03:14:21,825 - Epoch: [10][   83/   83]    Overall Loss 0.039138    Objective Loss 0.039138    Top1 100.000000    LR 0.000500    Time 0.039920    
2022-05-25 03:14:21,957 - --- validate (epoch=10)-----------
2022-05-25 03:14:21,957 - 912 samples (100 per mini-batch)
2022-05-25 03:14:22,379 - Epoch: [10][   10/   10]    Loss 0.018528    Top1 99.780702    
2022-05-25 03:14:22,444 - ==> Top1: 99.781    Loss: 0.019

2022-05-25 03:14:22,445 - ==> Confusion:
[[334   1]
 [  1 576]]

2022-05-25 03:14:22,487 - ==> Best [Top1: 99.781   Sparsity:0.00   Params: 177072 on epoch: 10]
2022-05-25 03:14:22,487 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:22,538 - 

2022-05-25 03:14:22,538 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:23,146 - Epoch: [11][   10/   83]    Overall Loss 0.008530    Objective Loss 0.008530                                        LR 0.000500    Time 0.060687    
2022-05-25 03:14:23,589 - Epoch: [11][   20/   83]    Overall Loss 0.008095    Objective Loss 0.008095                                        LR 0.000500    Time 0.049171    
2022-05-25 03:14:24,010 - Epoch: [11][   30/   83]    Overall Loss 0.005457    Objective Loss 0.005457                                        LR 0.000500    Time 0.045024    
2022-05-25 03:14:24,430 - Epoch: [11][   40/   83]    Overall Loss 0.006123    Objective Loss 0.006123                                        LR 0.000500    Time 0.042965    
2022-05-25 03:14:24,856 - Epoch: [11][   50/   83]    Overall Loss 0.004932    Objective Loss 0.004932                                        LR 0.000500    Time 0.041844    
2022-05-25 03:14:25,274 - Epoch: [11][   60/   83]    Overall Loss 0.005891    Objective Loss 0.005891                                        LR 0.000500    Time 0.040997    
2022-05-25 03:14:25,699 - Epoch: [11][   70/   83]    Overall Loss 0.005093    Objective Loss 0.005093                                        LR 0.000500    Time 0.040500    
2022-05-25 03:14:26,117 - Epoch: [11][   80/   83]    Overall Loss 0.004573    Objective Loss 0.004573                                        LR 0.000500    Time 0.039996    
2022-05-25 03:14:26,262 - Epoch: [11][   83/   83]    Overall Loss 0.004473    Objective Loss 0.004473    Top1 100.000000    LR 0.000500    Time 0.039676    
2022-05-25 03:14:26,384 - --- validate (epoch=11)-----------
2022-05-25 03:14:26,384 - 912 samples (100 per mini-batch)
2022-05-25 03:14:26,807 - Epoch: [11][   10/   10]    Loss 0.007519    Top1 99.890351    
2022-05-25 03:14:26,879 - ==> Top1: 99.890    Loss: 0.008

2022-05-25 03:14:26,879 - ==> Confusion:
[[334   1]
 [  0 577]]

2022-05-25 03:14:26,923 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 11]
2022-05-25 03:14:26,924 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:26,954 - 

2022-05-25 03:14:26,954 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:27,690 - Epoch: [12][   10/   83]    Overall Loss 0.006085    Objective Loss 0.006085                                        LR 0.000500    Time 0.073399    
2022-05-25 03:14:28,117 - Epoch: [12][   20/   83]    Overall Loss 0.004371    Objective Loss 0.004371                                        LR 0.000500    Time 0.054991    
2022-05-25 03:14:28,545 - Epoch: [12][   30/   83]    Overall Loss 0.002996    Objective Loss 0.002996                                        LR 0.000500    Time 0.049095    
2022-05-25 03:14:28,966 - Epoch: [12][   40/   83]    Overall Loss 0.002314    Objective Loss 0.002314                                        LR 0.000500    Time 0.046018    
2022-05-25 03:14:29,389 - Epoch: [12][   50/   83]    Overall Loss 0.001937    Objective Loss 0.001937                                        LR 0.000500    Time 0.044302    
2022-05-25 03:14:29,817 - Epoch: [12][   60/   83]    Overall Loss 0.001967    Objective Loss 0.001967                                        LR 0.000500    Time 0.043200    
2022-05-25 03:14:30,233 - Epoch: [12][   70/   83]    Overall Loss 0.002146    Objective Loss 0.002146                                        LR 0.000500    Time 0.042261    
2022-05-25 03:14:30,647 - Epoch: [12][   80/   83]    Overall Loss 0.002278    Objective Loss 0.002278                                        LR 0.000500    Time 0.041465    
2022-05-25 03:14:30,792 - Epoch: [12][   83/   83]    Overall Loss 0.002196    Objective Loss 0.002196    Top1 100.000000    LR 0.000500    Time 0.041087    
2022-05-25 03:14:30,913 - --- validate (epoch=12)-----------
2022-05-25 03:14:30,913 - 912 samples (100 per mini-batch)
2022-05-25 03:14:31,347 - Epoch: [12][   10/   10]    Loss 0.007292    Top1 99.671053    
2022-05-25 03:14:31,417 - ==> Top1: 99.671    Loss: 0.007

2022-05-25 03:14:31,417 - ==> Confusion:
[[333   2]
 [  1 576]]

2022-05-25 03:14:31,458 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 11]
2022-05-25 03:14:31,460 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:31,479 - 

2022-05-25 03:14:31,479 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:32,084 - Epoch: [13][   10/   83]    Overall Loss 0.000260    Objective Loss 0.000260                                        LR 0.000500    Time 0.060410    
2022-05-25 03:14:32,517 - Epoch: [13][   20/   83]    Overall Loss 0.000916    Objective Loss 0.000916                                        LR 0.000500    Time 0.048785    
2022-05-25 03:14:32,953 - Epoch: [13][   30/   83]    Overall Loss 0.002474    Objective Loss 0.002474                                        LR 0.000500    Time 0.044837    
2022-05-25 03:14:33,377 - Epoch: [13][   40/   83]    Overall Loss 0.001954    Objective Loss 0.001954                                        LR 0.000500    Time 0.042919    
2022-05-25 03:14:33,810 - Epoch: [13][   50/   83]    Overall Loss 0.001637    Objective Loss 0.001637                                        LR 0.000500    Time 0.041749    
2022-05-25 03:14:34,236 - Epoch: [13][   60/   83]    Overall Loss 0.001601    Objective Loss 0.001601                                        LR 0.000500    Time 0.040979    
2022-05-25 03:14:34,659 - Epoch: [13][   70/   83]    Overall Loss 0.001430    Objective Loss 0.001430                                        LR 0.000500    Time 0.040424    
2022-05-25 03:14:35,071 - Epoch: [13][   80/   83]    Overall Loss 0.001717    Objective Loss 0.001717                                        LR 0.000500    Time 0.039864    
2022-05-25 03:14:35,208 - Epoch: [13][   83/   83]    Overall Loss 0.001671    Objective Loss 0.001671    Top1 100.000000    LR 0.000500    Time 0.039445    
2022-05-25 03:14:35,337 - --- validate (epoch=13)-----------
2022-05-25 03:14:35,338 - 912 samples (100 per mini-batch)
2022-05-25 03:14:35,749 - Epoch: [13][   10/   10]    Loss 0.001207    Top1 99.890351    
2022-05-25 03:14:35,823 - ==> Top1: 99.890    Loss: 0.001

2022-05-25 03:14:35,823 - ==> Confusion:
[[335   0]
 [  1 576]]

2022-05-25 03:14:35,867 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 13]
2022-05-25 03:14:35,867 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:35,899 - 

2022-05-25 03:14:35,901 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:36,509 - Epoch: [14][   10/   83]    Overall Loss 0.006605    Objective Loss 0.006605                                        LR 0.000500    Time 0.060646    
2022-05-25 03:14:36,946 - Epoch: [14][   20/   83]    Overall Loss 0.003463    Objective Loss 0.003463                                        LR 0.000500    Time 0.048580    
2022-05-25 03:14:37,368 - Epoch: [14][   30/   83]    Overall Loss 0.003614    Objective Loss 0.003614                                        LR 0.000500    Time 0.044764    
2022-05-25 03:14:37,807 - Epoch: [14][   40/   83]    Overall Loss 0.002990    Objective Loss 0.002990                                        LR 0.000500    Time 0.043184    
2022-05-25 03:14:38,236 - Epoch: [14][   50/   83]    Overall Loss 0.002400    Objective Loss 0.002400                                        LR 0.000500    Time 0.041956    
2022-05-25 03:14:38,673 - Epoch: [14][   60/   83]    Overall Loss 0.002021    Objective Loss 0.002021                                        LR 0.000500    Time 0.041061    
2022-05-25 03:14:39,102 - Epoch: [14][   70/   83]    Overall Loss 0.001745    Objective Loss 0.001745                                        LR 0.000500    Time 0.040511    
2022-05-25 03:14:39,536 - Epoch: [14][   80/   83]    Overall Loss 0.001539    Objective Loss 0.001539                                        LR 0.000500    Time 0.040210    
2022-05-25 03:14:39,695 - Epoch: [14][   83/   83]    Overall Loss 0.001485    Objective Loss 0.001485    Top1 100.000000    LR 0.000500    Time 0.039795    
2022-05-25 03:14:39,810 - --- validate (epoch=14)-----------
2022-05-25 03:14:39,810 - 912 samples (100 per mini-batch)
2022-05-25 03:14:40,243 - Epoch: [14][   10/   10]    Loss 0.002060    Top1 99.890351    
2022-05-25 03:14:40,322 - ==> Top1: 99.890    Loss: 0.002

2022-05-25 03:14:40,322 - ==> Confusion:
[[334   1]
 [  0 577]]

2022-05-25 03:14:40,363 - ==> Best [Top1: 99.890   Sparsity:0.00   Params: 177072 on epoch: 14]
2022-05-25 03:14:40,364 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:40,395 - 

2022-05-25 03:14:40,397 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:41,011 - Epoch: [15][   10/   83]    Overall Loss 0.000057    Objective Loss 0.000057                                        LR 0.000500    Time 0.060764    
2022-05-25 03:14:41,438 - Epoch: [15][   20/   83]    Overall Loss 0.000049    Objective Loss 0.000049                                        LR 0.000500    Time 0.048815    
2022-05-25 03:14:41,864 - Epoch: [15][   30/   83]    Overall Loss 0.000039    Objective Loss 0.000039                                        LR 0.000500    Time 0.044708    
2022-05-25 03:14:42,299 - Epoch: [15][   40/   83]    Overall Loss 0.000042    Objective Loss 0.000042                                        LR 0.000500    Time 0.043093    
2022-05-25 03:14:42,725 - Epoch: [15][   50/   83]    Overall Loss 0.000042    Objective Loss 0.000042                                        LR 0.000500    Time 0.041828    
2022-05-25 03:14:43,147 - Epoch: [15][   60/   83]    Overall Loss 0.000059    Objective Loss 0.000059                                        LR 0.000500    Time 0.041025    
2022-05-25 03:14:43,577 - Epoch: [15][   70/   83]    Overall Loss 0.000063    Objective Loss 0.000063                                        LR 0.000500    Time 0.040442    
2022-05-25 03:14:43,996 - Epoch: [15][   80/   83]    Overall Loss 0.000153    Objective Loss 0.000153                                        LR 0.000500    Time 0.039832    
2022-05-25 03:14:44,133 - Epoch: [15][   83/   83]    Overall Loss 0.000148    Objective Loss 0.000148    Top1 100.000000    LR 0.000500    Time 0.039428    
2022-05-25 03:14:44,259 - --- validate (epoch=15)-----------
2022-05-25 03:14:44,259 - 912 samples (100 per mini-batch)
2022-05-25 03:14:44,690 - Epoch: [15][   10/   10]    Loss 0.000261    Top1 100.000000    
2022-05-25 03:14:44,760 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:14:44,761 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:14:44,803 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 15]
2022-05-25 03:14:44,803 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:44,838 - 

2022-05-25 03:14:44,839 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:45,466 - Epoch: [16][   10/   83]    Overall Loss 0.000401    Objective Loss 0.000401                                        LR 0.000500    Time 0.062579    
2022-05-25 03:14:45,908 - Epoch: [16][   20/   83]    Overall Loss 0.000218    Objective Loss 0.000218                                        LR 0.000500    Time 0.050327    
2022-05-25 03:14:46,330 - Epoch: [16][   30/   83]    Overall Loss 0.000161    Objective Loss 0.000161                                        LR 0.000500    Time 0.046049    
2022-05-25 03:14:46,754 - Epoch: [16][   40/   83]    Overall Loss 0.000174    Objective Loss 0.000174                                        LR 0.000500    Time 0.043905    
2022-05-25 03:14:47,177 - Epoch: [16][   50/   83]    Overall Loss 0.000151    Objective Loss 0.000151                                        LR 0.000500    Time 0.042512    
2022-05-25 03:14:47,606 - Epoch: [16][   60/   83]    Overall Loss 0.000131    Objective Loss 0.000131                                        LR 0.000500    Time 0.041760    
2022-05-25 03:14:48,030 - Epoch: [16][   70/   83]    Overall Loss 0.000116    Objective Loss 0.000116                                        LR 0.000500    Time 0.041030    
2022-05-25 03:14:48,438 - Epoch: [16][   80/   83]    Overall Loss 0.000116    Objective Loss 0.000116                                        LR 0.000500    Time 0.040363    
2022-05-25 03:14:48,584 - Epoch: [16][   83/   83]    Overall Loss 0.000118    Objective Loss 0.000118    Top1 100.000000    LR 0.000500    Time 0.040065    
2022-05-25 03:14:48,715 - --- validate (epoch=16)-----------
2022-05-25 03:14:48,716 - 912 samples (100 per mini-batch)
2022-05-25 03:14:49,129 - Epoch: [16][   10/   10]    Loss 0.000281    Top1 100.000000    
2022-05-25 03:14:49,206 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:14:49,206 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:14:49,247 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 16]
2022-05-25 03:14:49,249 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:49,280 - 

2022-05-25 03:14:49,281 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:49,909 - Epoch: [17][   10/   83]    Overall Loss 0.000090    Objective Loss 0.000090                                        LR 0.000500    Time 0.062631    
2022-05-25 03:14:50,349 - Epoch: [17][   20/   83]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000500    Time 0.050383    
2022-05-25 03:14:50,781 - Epoch: [17][   30/   83]    Overall Loss 0.000067    Objective Loss 0.000067                                        LR 0.000500    Time 0.045825    
2022-05-25 03:14:51,216 - Epoch: [17][   40/   83]    Overall Loss 0.000059    Objective Loss 0.000059                                        LR 0.000500    Time 0.043753    
2022-05-25 03:14:51,641 - Epoch: [17][   50/   83]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000500    Time 0.042463    
2022-05-25 03:14:52,066 - Epoch: [17][   60/   83]    Overall Loss 0.000053    Objective Loss 0.000053                                        LR 0.000500    Time 0.041490    
2022-05-25 03:14:52,485 - Epoch: [17][   70/   83]    Overall Loss 0.000049    Objective Loss 0.000049                                        LR 0.000500    Time 0.040791    
2022-05-25 03:14:52,905 - Epoch: [17][   80/   83]    Overall Loss 0.000048    Objective Loss 0.000048                                        LR 0.000500    Time 0.040138    
2022-05-25 03:14:53,049 - Epoch: [17][   83/   83]    Overall Loss 0.000046    Objective Loss 0.000046    Top1 100.000000    LR 0.000500    Time 0.039759    
2022-05-25 03:14:53,170 - --- validate (epoch=17)-----------
2022-05-25 03:14:53,170 - 912 samples (100 per mini-batch)
2022-05-25 03:14:53,589 - Epoch: [17][   10/   10]    Loss 0.000451    Top1 100.000000    
2022-05-25 03:14:53,662 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:14:53,662 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:14:53,703 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 17]
2022-05-25 03:14:53,703 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:53,739 - 

2022-05-25 03:14:53,739 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:54,365 - Epoch: [18][   10/   83]    Overall Loss 0.000037    Objective Loss 0.000037                                        LR 0.000500    Time 0.062496    
2022-05-25 03:14:54,790 - Epoch: [18][   20/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000500    Time 0.049259    
2022-05-25 03:14:55,217 - Epoch: [18][   30/   83]    Overall Loss 0.000027    Objective Loss 0.000027                                        LR 0.000500    Time 0.045450    
2022-05-25 03:14:55,644 - Epoch: [18][   40/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000500    Time 0.043248    
2022-05-25 03:14:56,072 - Epoch: [18][   50/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000500    Time 0.041939    
2022-05-25 03:14:56,489 - Epoch: [18][   60/   83]    Overall Loss 0.000032    Objective Loss 0.000032                                        LR 0.000500    Time 0.041003    
2022-05-25 03:14:56,926 - Epoch: [18][   70/   83]    Overall Loss 0.000042    Objective Loss 0.000042                                        LR 0.000500    Time 0.040646    
2022-05-25 03:14:57,351 - Epoch: [18][   80/   83]    Overall Loss 0.000041    Objective Loss 0.000041                                        LR 0.000500    Time 0.040192    
2022-05-25 03:14:57,496 - Epoch: [18][   83/   83]    Overall Loss 0.000040    Objective Loss 0.000040    Top1 100.000000    LR 0.000500    Time 0.039864    
2022-05-25 03:14:57,618 - --- validate (epoch=18)-----------
2022-05-25 03:14:57,618 - 912 samples (100 per mini-batch)
2022-05-25 03:14:58,031 - Epoch: [18][   10/   10]    Loss 0.000262    Top1 100.000000    
2022-05-25 03:14:58,102 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:14:58,102 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:14:58,143 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 18]
2022-05-25 03:14:58,143 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:14:58,174 - 

2022-05-25 03:14:58,174 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:14:58,792 - Epoch: [19][   10/   83]    Overall Loss 0.000036    Objective Loss 0.000036                                        LR 0.000500    Time 0.061684    
2022-05-25 03:14:59,228 - Epoch: [19][   20/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000500    Time 0.049500    
2022-05-25 03:14:59,644 - Epoch: [19][   30/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000500    Time 0.045265    
2022-05-25 03:15:00,073 - Epoch: [19][   40/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000500    Time 0.043108    
2022-05-25 03:15:00,497 - Epoch: [19][   50/   83]    Overall Loss 0.000037    Objective Loss 0.000037                                        LR 0.000500    Time 0.041837    
2022-05-25 03:15:00,919 - Epoch: [19][   60/   83]    Overall Loss 0.000036    Objective Loss 0.000036                                        LR 0.000500    Time 0.040911    
2022-05-25 03:15:01,340 - Epoch: [19][   70/   83]    Overall Loss 0.000033    Objective Loss 0.000033                                        LR 0.000500    Time 0.040357    
2022-05-25 03:15:01,754 - Epoch: [19][   80/   83]    Overall Loss 0.000035    Objective Loss 0.000035                                        LR 0.000500    Time 0.039802    
2022-05-25 03:15:01,893 - Epoch: [19][   83/   83]    Overall Loss 0.000034    Objective Loss 0.000034    Top1 100.000000    LR 0.000500    Time 0.039427    
2022-05-25 03:15:02,014 - --- validate (epoch=19)-----------
2022-05-25 03:15:02,014 - 912 samples (100 per mini-batch)
2022-05-25 03:15:02,442 - Epoch: [19][   10/   10]    Loss 0.000237    Top1 100.000000    
2022-05-25 03:15:02,512 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:02,512 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:02,554 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 19]
2022-05-25 03:15:02,556 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:02,593 - 

2022-05-25 03:15:02,593 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:03,216 - Epoch: [20][   10/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000250    Time 0.062162    
2022-05-25 03:15:03,637 - Epoch: [20][   20/   83]    Overall Loss 0.000033    Objective Loss 0.000033                                        LR 0.000250    Time 0.049071    
2022-05-25 03:15:04,066 - Epoch: [20][   30/   83]    Overall Loss 0.000032    Objective Loss 0.000032                                        LR 0.000250    Time 0.044841    
2022-05-25 03:15:04,494 - Epoch: [20][   40/   83]    Overall Loss 0.000027    Objective Loss 0.000027                                        LR 0.000250    Time 0.043121    
2022-05-25 03:15:04,908 - Epoch: [20][   50/   83]    Overall Loss 0.000034    Objective Loss 0.000034                                        LR 0.000250    Time 0.041759    
2022-05-25 03:15:05,328 - Epoch: [20][   60/   83]    Overall Loss 0.000031    Objective Loss 0.000031                                        LR 0.000250    Time 0.040783    
2022-05-25 03:15:05,751 - Epoch: [20][   70/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.040207    
2022-05-25 03:15:06,170 - Epoch: [20][   80/   83]    Overall Loss 0.000030    Objective Loss 0.000030                                        LR 0.000250    Time 0.039783    
2022-05-25 03:15:06,301 - Epoch: [20][   83/   83]    Overall Loss 0.000030    Objective Loss 0.000030    Top1 100.000000    LR 0.000250    Time 0.039392    
2022-05-25 03:15:06,428 - --- validate (epoch=20)-----------
2022-05-25 03:15:06,428 - 912 samples (100 per mini-batch)
2022-05-25 03:15:06,849 - Epoch: [20][   10/   10]    Loss 0.000227    Top1 100.000000    
2022-05-25 03:15:06,922 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:06,922 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:06,966 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 20]
2022-05-25 03:15:06,967 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:06,996 - 

2022-05-25 03:15:06,997 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:07,630 - Epoch: [21][   10/   83]    Overall Loss 0.000025    Objective Loss 0.000025                                        LR 0.000250    Time 0.063135    
2022-05-25 03:15:08,052 - Epoch: [21][   20/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.049498    
2022-05-25 03:15:08,474 - Epoch: [21][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.045135    
2022-05-25 03:15:08,908 - Epoch: [21][   40/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000250    Time 0.043159    
2022-05-25 03:15:09,329 - Epoch: [21][   50/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000250    Time 0.041897    
2022-05-25 03:15:09,745 - Epoch: [21][   60/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.040935    
2022-05-25 03:15:10,182 - Epoch: [21][   70/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000250    Time 0.040437    
2022-05-25 03:15:10,598 - Epoch: [21][   80/   83]    Overall Loss 0.000030    Objective Loss 0.000030                                        LR 0.000250    Time 0.039940    
2022-05-25 03:15:10,740 - Epoch: [21][   83/   83]    Overall Loss 0.000029    Objective Loss 0.000029    Top1 100.000000    LR 0.000250    Time 0.039529    
2022-05-25 03:15:10,861 - --- validate (epoch=21)-----------
2022-05-25 03:15:10,861 - 912 samples (100 per mini-batch)
2022-05-25 03:15:11,289 - Epoch: [21][   10/   10]    Loss 0.000217    Top1 100.000000    
2022-05-25 03:15:11,359 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:11,360 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:11,402 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 21]
2022-05-25 03:15:11,403 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:11,435 - 

2022-05-25 03:15:11,436 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:12,042 - Epoch: [22][   10/   83]    Overall Loss 0.000032    Objective Loss 0.000032                                        LR 0.000250    Time 0.060430    
2022-05-25 03:15:12,460 - Epoch: [22][   20/   83]    Overall Loss 0.000043    Objective Loss 0.000043                                        LR 0.000250    Time 0.048178    
2022-05-25 03:15:12,886 - Epoch: [22][   30/   83]    Overall Loss 0.000035    Objective Loss 0.000035                                        LR 0.000250    Time 0.044415    
2022-05-25 03:15:13,310 - Epoch: [22][   40/   83]    Overall Loss 0.000032    Objective Loss 0.000032                                        LR 0.000250    Time 0.042368    
2022-05-25 03:15:13,744 - Epoch: [22][   50/   83]    Overall Loss 0.000031    Objective Loss 0.000031                                        LR 0.000250    Time 0.041331    
2022-05-25 03:15:14,172 - Epoch: [22][   60/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000250    Time 0.040481    
2022-05-25 03:15:14,588 - Epoch: [22][   70/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000250    Time 0.039914    
2022-05-25 03:15:14,997 - Epoch: [22][   80/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000250    Time 0.039348    
2022-05-25 03:15:15,141 - Epoch: [22][   83/   83]    Overall Loss 0.000028    Objective Loss 0.000028    Top1 100.000000    LR 0.000250    Time 0.039059    
2022-05-25 03:15:15,276 - --- validate (epoch=22)-----------
2022-05-25 03:15:15,276 - 912 samples (100 per mini-batch)
2022-05-25 03:15:15,707 - Epoch: [22][   10/   10]    Loss 0.000208    Top1 100.000000    
2022-05-25 03:15:15,794 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:15,794 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:15,838 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 22]
2022-05-25 03:15:15,839 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:15,872 - 

2022-05-25 03:15:15,873 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:16,492 - Epoch: [23][   10/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.061745    
2022-05-25 03:15:16,932 - Epoch: [23][   20/   83]    Overall Loss 0.000044    Objective Loss 0.000044                                        LR 0.000250    Time 0.049845    
2022-05-25 03:15:17,340 - Epoch: [23][   30/   83]    Overall Loss 0.000034    Objective Loss 0.000034                                        LR 0.000250    Time 0.045373    
2022-05-25 03:15:17,771 - Epoch: [23][   40/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.043242    
2022-05-25 03:15:18,186 - Epoch: [23][   50/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.041832    
2022-05-25 03:15:18,615 - Epoch: [23][   60/   83]    Overall Loss 0.000026    Objective Loss 0.000026                                        LR 0.000250    Time 0.040978    
2022-05-25 03:15:19,040 - Epoch: [23][   70/   83]    Overall Loss 0.000027    Objective Loss 0.000027                                        LR 0.000250    Time 0.040350    
2022-05-25 03:15:19,461 - Epoch: [23][   80/   83]    Overall Loss 0.000027    Objective Loss 0.000027                                        LR 0.000250    Time 0.039798    
2022-05-25 03:15:19,610 - Epoch: [23][   83/   83]    Overall Loss 0.000026    Objective Loss 0.000026    Top1 100.000000    LR 0.000250    Time 0.039483    
2022-05-25 03:15:19,727 - --- validate (epoch=23)-----------
2022-05-25 03:15:19,727 - 912 samples (100 per mini-batch)
2022-05-25 03:15:20,139 - Epoch: [23][   10/   10]    Loss 0.000198    Top1 100.000000    
2022-05-25 03:15:20,209 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:20,209 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:20,251 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 23]
2022-05-25 03:15:20,252 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:20,287 - 

2022-05-25 03:15:20,288 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:20,905 - Epoch: [24][   10/   83]    Overall Loss 0.000044    Objective Loss 0.000044                                        LR 0.000250    Time 0.061510    
2022-05-25 03:15:21,343 - Epoch: [24][   20/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.049299    
2022-05-25 03:15:21,775 - Epoch: [24][   30/   83]    Overall Loss 0.000031    Objective Loss 0.000031                                        LR 0.000250    Time 0.045106    
2022-05-25 03:15:22,185 - Epoch: [24][   40/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.042902    
2022-05-25 03:15:22,621 - Epoch: [24][   50/   83]    Overall Loss 0.000025    Objective Loss 0.000025                                        LR 0.000250    Time 0.041711    
2022-05-25 03:15:23,046 - Epoch: [24][   60/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000250    Time 0.040864    
2022-05-25 03:15:23,469 - Epoch: [24][   70/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000250    Time 0.040218    
2022-05-25 03:15:23,909 - Epoch: [24][   80/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000250    Time 0.039764    
2022-05-25 03:15:24,055 - Epoch: [24][   83/   83]    Overall Loss 0.000035    Objective Loss 0.000035    Top1 100.000000    LR 0.000250    Time 0.039460    
2022-05-25 03:15:24,175 - --- validate (epoch=24)-----------
2022-05-25 03:15:24,175 - 912 samples (100 per mini-batch)
2022-05-25 03:15:24,610 - Epoch: [24][   10/   10]    Loss 0.000192    Top1 100.000000    
2022-05-25 03:15:24,690 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:24,690 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:24,731 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 24]
2022-05-25 03:15:24,732 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:24,762 - 

2022-05-25 03:15:24,764 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:25,369 - Epoch: [25][   10/   83]    Overall Loss 0.000032    Objective Loss 0.000032                                        LR 0.000250    Time 0.060228    
2022-05-25 03:15:25,792 - Epoch: [25][   20/   83]    Overall Loss 0.000030    Objective Loss 0.000030                                        LR 0.000250    Time 0.048257    
2022-05-25 03:15:26,217 - Epoch: [25][   30/   83]    Overall Loss 0.000033    Objective Loss 0.000033                                        LR 0.000250    Time 0.044566    
2022-05-25 03:15:26,646 - Epoch: [25][   40/   83]    Overall Loss 0.000032    Objective Loss 0.000032                                        LR 0.000250    Time 0.042528    
2022-05-25 03:15:27,082 - Epoch: [25][   50/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.041494    
2022-05-25 03:15:27,510 - Epoch: [25][   60/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000250    Time 0.040904    
2022-05-25 03:15:27,948 - Epoch: [25][   70/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.040499    
2022-05-25 03:15:28,366 - Epoch: [25][   80/   83]    Overall Loss 0.000026    Objective Loss 0.000026                                        LR 0.000250    Time 0.039876    
2022-05-25 03:15:28,511 - Epoch: [25][   83/   83]    Overall Loss 0.000025    Objective Loss 0.000025    Top1 100.000000    LR 0.000250    Time 0.039458    
2022-05-25 03:15:28,657 - --- validate (epoch=25)-----------
2022-05-25 03:15:28,657 - 912 samples (100 per mini-batch)
2022-05-25 03:15:29,078 - Epoch: [25][   10/   10]    Loss 0.000180    Top1 100.000000    
2022-05-25 03:15:29,155 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:29,156 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:29,200 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 25]
2022-05-25 03:15:29,201 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:29,228 - 

2022-05-25 03:15:29,229 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:29,847 - Epoch: [26][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.061640    
2022-05-25 03:15:30,277 - Epoch: [26][   20/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000250    Time 0.049392    
2022-05-25 03:15:30,685 - Epoch: [26][   30/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000250    Time 0.045166    
2022-05-25 03:15:31,107 - Epoch: [26][   40/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.042938    
2022-05-25 03:15:31,519 - Epoch: [26][   50/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000250    Time 0.041704    
2022-05-25 03:15:31,950 - Epoch: [26][   60/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.040854    
2022-05-25 03:15:32,375 - Epoch: [26][   70/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.040406    
2022-05-25 03:15:32,796 - Epoch: [26][   80/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.039835    
2022-05-25 03:15:32,933 - Epoch: [26][   83/   83]    Overall Loss 0.000022    Objective Loss 0.000022    Top1 100.000000    LR 0.000250    Time 0.039423    
2022-05-25 03:15:33,055 - --- validate (epoch=26)-----------
2022-05-25 03:15:33,055 - 912 samples (100 per mini-batch)
2022-05-25 03:15:33,471 - Epoch: [26][   10/   10]    Loss 0.000330    Top1 100.000000    
2022-05-25 03:15:33,543 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:33,543 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:33,587 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 26]
2022-05-25 03:15:33,587 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:33,623 - 

2022-05-25 03:15:33,624 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:34,247 - Epoch: [27][   10/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.062187    
2022-05-25 03:15:34,678 - Epoch: [27][   20/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000250    Time 0.049168    
2022-05-25 03:15:35,105 - Epoch: [27][   30/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000250    Time 0.045139    
2022-05-25 03:15:35,537 - Epoch: [27][   40/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000250    Time 0.042999    
2022-05-25 03:15:35,962 - Epoch: [27][   50/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.041857    
2022-05-25 03:15:36,377 - Epoch: [27][   60/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.041078    
2022-05-25 03:15:36,814 - Epoch: [27][   70/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000250    Time 0.040743    
2022-05-25 03:15:37,234 - Epoch: [27][   80/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.040099    
2022-05-25 03:15:37,371 - Epoch: [27][   83/   83]    Overall Loss 0.000021    Objective Loss 0.000021    Top1 100.000000    LR 0.000250    Time 0.039705    
2022-05-25 03:15:37,497 - --- validate (epoch=27)-----------
2022-05-25 03:15:37,498 - 912 samples (100 per mini-batch)
2022-05-25 03:15:37,917 - Epoch: [27][   10/   10]    Loss 0.000178    Top1 100.000000    
2022-05-25 03:15:37,999 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:37,999 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:38,041 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 27]
2022-05-25 03:15:38,042 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:38,079 - 

2022-05-25 03:15:38,081 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:38,692 - Epoch: [28][   10/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000250    Time 0.060968    
2022-05-25 03:15:39,122 - Epoch: [28][   20/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.048897    
2022-05-25 03:15:39,552 - Epoch: [28][   30/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.044723    
2022-05-25 03:15:39,984 - Epoch: [28][   40/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.042867    
2022-05-25 03:15:40,413 - Epoch: [28][   50/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.041643    
2022-05-25 03:15:40,843 - Epoch: [28][   60/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.040867    
2022-05-25 03:15:41,269 - Epoch: [28][   70/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.040256    
2022-05-25 03:15:41,695 - Epoch: [28][   80/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.039899    
2022-05-25 03:15:41,841 - Epoch: [28][   83/   83]    Overall Loss 0.000022    Objective Loss 0.000022    Top1 100.000000    LR 0.000250    Time 0.039583    
2022-05-25 03:15:41,962 - --- validate (epoch=28)-----------
2022-05-25 03:15:41,962 - 912 samples (100 per mini-batch)
2022-05-25 03:15:42,383 - Epoch: [28][   10/   10]    Loss 0.000264    Top1 100.000000    
2022-05-25 03:15:42,466 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:42,467 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:42,508 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 28]
2022-05-25 03:15:42,509 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:42,542 - 

2022-05-25 03:15:42,543 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:43,147 - Epoch: [29][   10/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.060164    
2022-05-25 03:15:43,576 - Epoch: [29][   20/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000250    Time 0.048495    
2022-05-25 03:15:44,001 - Epoch: [29][   30/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000250    Time 0.044513    
2022-05-25 03:15:44,419 - Epoch: [29][   40/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.042482    
2022-05-25 03:15:44,844 - Epoch: [29][   50/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.041388    
2022-05-25 03:15:45,263 - Epoch: [29][   60/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.040536    
2022-05-25 03:15:45,681 - Epoch: [29][   70/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.039976    
2022-05-25 03:15:46,104 - Epoch: [29][   80/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.039463    
2022-05-25 03:15:46,249 - Epoch: [29][   83/   83]    Overall Loss 0.000019    Objective Loss 0.000019    Top1 100.000000    LR 0.000250    Time 0.039168    
2022-05-25 03:15:46,367 - --- validate (epoch=29)-----------
2022-05-25 03:15:46,368 - 912 samples (100 per mini-batch)
2022-05-25 03:15:46,794 - Epoch: [29][   10/   10]    Loss 0.000235    Top1 100.000000    
2022-05-25 03:15:46,875 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:46,875 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:46,918 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 29]
2022-05-25 03:15:46,918 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:46,968 - 

2022-05-25 03:15:46,968 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:47,589 - Epoch: [30][   10/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.061952    
2022-05-25 03:15:48,026 - Epoch: [30][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000250    Time 0.049798    
2022-05-25 03:15:48,463 - Epoch: [30][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000250    Time 0.045474    
2022-05-25 03:15:48,886 - Epoch: [30][   40/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000250    Time 0.043392    
2022-05-25 03:15:49,314 - Epoch: [30][   50/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.041990    
2022-05-25 03:15:49,746 - Epoch: [30][   60/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.041052    
2022-05-25 03:15:50,171 - Epoch: [30][   70/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.040397    
2022-05-25 03:15:50,579 - Epoch: [30][   80/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.039781    
2022-05-25 03:15:50,720 - Epoch: [30][   83/   83]    Overall Loss 0.000019    Objective Loss 0.000019    Top1 100.000000    LR 0.000250    Time 0.039380    
2022-05-25 03:15:50,843 - --- validate (epoch=30)-----------
2022-05-25 03:15:50,843 - 912 samples (100 per mini-batch)
2022-05-25 03:15:51,268 - Epoch: [30][   10/   10]    Loss 0.000202    Top1 100.000000    
2022-05-25 03:15:51,340 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:51,340 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:51,381 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 30]
2022-05-25 03:15:51,383 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:51,415 - 

2022-05-25 03:15:51,416 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:52,026 - Epoch: [31][   10/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.060839    
2022-05-25 03:15:52,454 - Epoch: [31][   20/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.048401    
2022-05-25 03:15:52,869 - Epoch: [31][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.044307    
2022-05-25 03:15:53,306 - Epoch: [31][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000250    Time 0.042673    
2022-05-25 03:15:53,727 - Epoch: [31][   50/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.041497    
2022-05-25 03:15:54,155 - Epoch: [31][   60/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.040869    
2022-05-25 03:15:54,579 - Epoch: [31][   70/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.040333    
2022-05-25 03:15:54,994 - Epoch: [31][   80/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.039710    
2022-05-25 03:15:55,131 - Epoch: [31][   83/   83]    Overall Loss 0.000018    Objective Loss 0.000018    Top1 100.000000    LR 0.000250    Time 0.039312    
2022-05-25 03:15:55,252 - --- validate (epoch=31)-----------
2022-05-25 03:15:55,253 - 912 samples (100 per mini-batch)
2022-05-25 03:15:55,679 - Epoch: [31][   10/   10]    Loss 0.000170    Top1 100.000000    
2022-05-25 03:15:55,766 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:15:55,767 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:15:55,807 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 31]
2022-05-25 03:15:55,809 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:15:55,839 - 

2022-05-25 03:15:55,841 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:15:56,542 - Epoch: [32][   10/   83]    Overall Loss 0.000047    Objective Loss 0.000047                                        LR 0.000250    Time 0.069957    
2022-05-25 03:15:56,969 - Epoch: [32][   20/   83]    Overall Loss 0.000033    Objective Loss 0.000033                                        LR 0.000250    Time 0.052944    
2022-05-25 03:15:57,388 - Epoch: [32][   30/   83]    Overall Loss 0.000025    Objective Loss 0.000025                                        LR 0.000250    Time 0.047458    
2022-05-25 03:15:57,798 - Epoch: [32][   40/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.044719    
2022-05-25 03:15:58,227 - Epoch: [32][   50/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.043312    
2022-05-25 03:15:58,653 - Epoch: [32][   60/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.042303    
2022-05-25 03:15:59,084 - Epoch: [32][   70/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.041673    
2022-05-25 03:15:59,507 - Epoch: [32][   80/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040946    
2022-05-25 03:15:59,648 - Epoch: [32][   83/   83]    Overall Loss 0.000017    Objective Loss 0.000017    Top1 100.000000    LR 0.000250    Time 0.040606    
2022-05-25 03:15:59,768 - --- validate (epoch=32)-----------
2022-05-25 03:15:59,768 - 912 samples (100 per mini-batch)
2022-05-25 03:16:00,214 - Epoch: [32][   10/   10]    Loss 0.000178    Top1 100.000000    
2022-05-25 03:16:00,284 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:00,285 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:00,326 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 32]
2022-05-25 03:16:00,327 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:00,358 - 

2022-05-25 03:16:00,360 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:00,967 - Epoch: [33][   10/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.060584    
2022-05-25 03:16:01,401 - Epoch: [33][   20/   83]    Overall Loss 0.000027    Objective Loss 0.000027                                        LR 0.000250    Time 0.048547    
2022-05-25 03:16:01,824 - Epoch: [33][   30/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.044752    
2022-05-25 03:16:02,251 - Epoch: [33][   40/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.042606    
2022-05-25 03:16:02,681 - Epoch: [33][   50/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000250    Time 0.041440    
2022-05-25 03:16:03,104 - Epoch: [33][   60/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040678    
2022-05-25 03:16:03,537 - Epoch: [33][   70/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040252    
2022-05-25 03:16:03,972 - Epoch: [33][   80/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.039923    
2022-05-25 03:16:04,110 - Epoch: [33][   83/   83]    Overall Loss 0.000017    Objective Loss 0.000017    Top1 100.000000    LR 0.000250    Time 0.039525    
2022-05-25 03:16:04,248 - --- validate (epoch=33)-----------
2022-05-25 03:16:04,249 - 912 samples (100 per mini-batch)
2022-05-25 03:16:04,666 - Epoch: [33][   10/   10]    Loss 0.000177    Top1 100.000000    
2022-05-25 03:16:04,735 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:04,735 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:04,778 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 33]
2022-05-25 03:16:04,779 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:04,820 - 

2022-05-25 03:16:04,820 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:05,428 - Epoch: [34][   10/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.060672    
2022-05-25 03:16:05,877 - Epoch: [34][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000250    Time 0.049357    
2022-05-25 03:16:06,314 - Epoch: [34][   30/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.045215    
2022-05-25 03:16:06,751 - Epoch: [34][   40/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.043233    
2022-05-25 03:16:07,188 - Epoch: [34][   50/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.041951    
2022-05-25 03:16:07,604 - Epoch: [34][   60/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.041121    
2022-05-25 03:16:08,029 - Epoch: [34][   70/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040603    
2022-05-25 03:16:08,470 - Epoch: [34][   80/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.040285    
2022-05-25 03:16:08,616 - Epoch: [34][   83/   83]    Overall Loss 0.000016    Objective Loss 0.000016    Top1 100.000000    LR 0.000250    Time 0.039956    
2022-05-25 03:16:08,741 - --- validate (epoch=34)-----------
2022-05-25 03:16:08,741 - 912 samples (100 per mini-batch)
2022-05-25 03:16:09,176 - Epoch: [34][   10/   10]    Loss 0.000194    Top1 100.000000    
2022-05-25 03:16:09,253 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:09,253 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:09,297 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177071 on epoch: 34]
2022-05-25 03:16:09,298 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:09,332 - 

2022-05-25 03:16:09,333 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:09,944 - Epoch: [35][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000250    Time 0.061033    
2022-05-25 03:16:10,380 - Epoch: [35][   20/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000250    Time 0.049348    
2022-05-25 03:16:10,809 - Epoch: [35][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000250    Time 0.045371    
2022-05-25 03:16:11,224 - Epoch: [35][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000250    Time 0.043183    
2022-05-25 03:16:11,651 - Epoch: [35][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000250    Time 0.041875    
2022-05-25 03:16:12,076 - Epoch: [35][   60/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000250    Time 0.040959    
2022-05-25 03:16:12,489 - Epoch: [35][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000250    Time 0.040368    
2022-05-25 03:16:12,896 - Epoch: [35][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.039765    
2022-05-25 03:16:13,035 - Epoch: [35][   83/   83]    Overall Loss 0.000016    Objective Loss 0.000016    Top1 100.000000    LR 0.000250    Time 0.039366    
2022-05-25 03:16:13,155 - --- validate (epoch=35)-----------
2022-05-25 03:16:13,155 - 912 samples (100 per mini-batch)
2022-05-25 03:16:13,585 - Epoch: [35][   10/   10]    Loss 0.000185    Top1 100.000000    
2022-05-25 03:16:13,670 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:13,671 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:13,712 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 35]
2022-05-25 03:16:13,713 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:13,751 - 

2022-05-25 03:16:13,753 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:14,356 - Epoch: [36][   10/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000250    Time 0.060137    
2022-05-25 03:16:14,781 - Epoch: [36][   20/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000250    Time 0.048608    
2022-05-25 03:16:15,214 - Epoch: [36][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.044581    
2022-05-25 03:16:15,641 - Epoch: [36][   40/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.042774    
2022-05-25 03:16:16,055 - Epoch: [36][   50/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.041468    
2022-05-25 03:16:16,468 - Epoch: [36][   60/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040560    
2022-05-25 03:16:16,889 - Epoch: [36][   70/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.039994    
2022-05-25 03:16:17,311 - Epoch: [36][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.039449    
2022-05-25 03:16:17,457 - Epoch: [36][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000250    Time 0.039153    
2022-05-25 03:16:17,574 - --- validate (epoch=36)-----------
2022-05-25 03:16:17,574 - 912 samples (100 per mini-batch)
2022-05-25 03:16:17,996 - Epoch: [36][   10/   10]    Loss 0.000210    Top1 100.000000    
2022-05-25 03:16:18,071 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:18,071 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:18,113 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 36]
2022-05-25 03:16:18,115 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:18,148 - 

2022-05-25 03:16:18,149 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:18,772 - Epoch: [37][   10/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000250    Time 0.062113    
2022-05-25 03:16:19,193 - Epoch: [37][   20/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.049179    
2022-05-25 03:16:19,626 - Epoch: [37][   30/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.045056    
2022-05-25 03:16:20,068 - Epoch: [37][   40/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.043262    
2022-05-25 03:16:20,502 - Epoch: [37][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.042012    
2022-05-25 03:16:20,924 - Epoch: [37][   60/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.041121    
2022-05-25 03:16:21,350 - Epoch: [37][   70/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040599    
2022-05-25 03:16:21,761 - Epoch: [37][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.039996    
2022-05-25 03:16:21,898 - Epoch: [37][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000250    Time 0.039575    
2022-05-25 03:16:22,027 - --- validate (epoch=37)-----------
2022-05-25 03:16:22,027 - 912 samples (100 per mini-batch)
2022-05-25 03:16:22,445 - Epoch: [37][   10/   10]    Loss 0.000191    Top1 100.000000    
2022-05-25 03:16:22,511 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:22,512 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:22,552 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 37]
2022-05-25 03:16:22,553 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:22,584 - 

2022-05-25 03:16:22,585 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:23,186 - Epoch: [38][   10/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.059995    
2022-05-25 03:16:23,615 - Epoch: [38][   20/   83]    Overall Loss 0.000028    Objective Loss 0.000028                                        LR 0.000250    Time 0.048395    
2022-05-25 03:16:24,035 - Epoch: [38][   30/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000250    Time 0.044474    
2022-05-25 03:16:24,462 - Epoch: [38][   40/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.042515    
2022-05-25 03:16:24,885 - Epoch: [38][   50/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000250    Time 0.041338    
2022-05-25 03:16:25,303 - Epoch: [38][   60/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000250    Time 0.040511    
2022-05-25 03:16:25,723 - Epoch: [38][   70/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.039929    
2022-05-25 03:16:26,142 - Epoch: [38][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.039375    
2022-05-25 03:16:26,283 - Epoch: [38][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000250    Time 0.039008    
2022-05-25 03:16:26,417 - --- validate (epoch=38)-----------
2022-05-25 03:16:26,418 - 912 samples (100 per mini-batch)
2022-05-25 03:16:26,848 - Epoch: [38][   10/   10]    Loss 0.000201    Top1 100.000000    
2022-05-25 03:16:26,916 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:26,916 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:26,957 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 38]
2022-05-25 03:16:26,957 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:26,996 - 

2022-05-25 03:16:26,996 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:27,595 - Epoch: [39][   10/   83]    Overall Loss 0.000006    Objective Loss 0.000006                                        LR 0.000250    Time 0.059750    
2022-05-25 03:16:28,014 - Epoch: [39][   20/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.047859    
2022-05-25 03:16:28,428 - Epoch: [39][   30/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000250    Time 0.043987    
2022-05-25 03:16:28,859 - Epoch: [39][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.042297    
2022-05-25 03:16:29,280 - Epoch: [39][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.041191    
2022-05-25 03:16:29,699 - Epoch: [39][   60/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000250    Time 0.040407    
2022-05-25 03:16:30,117 - Epoch: [39][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.039847    
2022-05-25 03:16:30,535 - Epoch: [39][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000250    Time 0.039427    
2022-05-25 03:16:30,692 - Epoch: [39][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000250    Time 0.039130    
2022-05-25 03:16:30,815 - --- validate (epoch=39)-----------
2022-05-25 03:16:30,816 - 912 samples (100 per mini-batch)
2022-05-25 03:16:31,229 - Epoch: [39][   10/   10]    Loss 0.000222    Top1 100.000000    
2022-05-25 03:16:31,302 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:31,302 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:31,345 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 39]
2022-05-25 03:16:31,347 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:31,377 - 

2022-05-25 03:16:31,379 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:32,008 - Epoch: [40][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.062783    
2022-05-25 03:16:32,442 - Epoch: [40][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.050037    
2022-05-25 03:16:32,870 - Epoch: [40][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.045519    
2022-05-25 03:16:33,295 - Epoch: [40][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.043164    
2022-05-25 03:16:33,719 - Epoch: [40][   50/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.041886    
2022-05-25 03:16:34,133 - Epoch: [40][   60/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.040893    
2022-05-25 03:16:34,548 - Epoch: [40][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040324    
2022-05-25 03:16:34,972 - Epoch: [40][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039690    
2022-05-25 03:16:35,117 - Epoch: [40][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039304    
2022-05-25 03:16:35,247 - --- validate (epoch=40)-----------
2022-05-25 03:16:35,247 - 912 samples (100 per mini-batch)
2022-05-25 03:16:35,675 - Epoch: [40][   10/   10]    Loss 0.000218    Top1 100.000000    
2022-05-25 03:16:35,745 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:35,745 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:35,788 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 40]
2022-05-25 03:16:35,789 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:35,819 - 

2022-05-25 03:16:35,820 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:36,428 - Epoch: [41][   10/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000125    Time 0.060674    
2022-05-25 03:16:36,848 - Epoch: [41][   20/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.048249    
2022-05-25 03:16:37,273 - Epoch: [41][   30/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000125    Time 0.044577    
2022-05-25 03:16:37,707 - Epoch: [41][   40/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000125    Time 0.042718    
2022-05-25 03:16:38,127 - Epoch: [41][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041520    
2022-05-25 03:16:38,546 - Epoch: [41][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040636    
2022-05-25 03:16:38,964 - Epoch: [41][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040113    
2022-05-25 03:16:39,381 - Epoch: [41][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039675    
2022-05-25 03:16:39,525 - Epoch: [41][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039373    
2022-05-25 03:16:39,658 - --- validate (epoch=41)-----------
2022-05-25 03:16:39,659 - 912 samples (100 per mini-batch)
2022-05-25 03:16:40,081 - Epoch: [41][   10/   10]    Loss 0.000203    Top1 100.000000    
2022-05-25 03:16:40,159 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:40,159 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:40,200 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 41]
2022-05-25 03:16:40,201 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:40,235 - 

2022-05-25 03:16:40,236 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:40,859 - Epoch: [42][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.062055    
2022-05-25 03:16:41,303 - Epoch: [42][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.050208    
2022-05-25 03:16:41,731 - Epoch: [42][   30/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.045654    
2022-05-25 03:16:42,149 - Epoch: [42][   40/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.043393    
2022-05-25 03:16:42,578 - Epoch: [42][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.042062    
2022-05-25 03:16:43,006 - Epoch: [42][   60/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.041328    
2022-05-25 03:16:43,428 - Epoch: [42][   70/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.040566    
2022-05-25 03:16:43,840 - Epoch: [42][   80/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.039984    
2022-05-25 03:16:43,984 - Epoch: [42][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039662    
2022-05-25 03:16:44,107 - --- validate (epoch=42)-----------
2022-05-25 03:16:44,107 - 912 samples (100 per mini-batch)
2022-05-25 03:16:44,538 - Epoch: [42][   10/   10]    Loss 0.000247    Top1 100.000000    
2022-05-25 03:16:44,622 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:44,622 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:44,663 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 42]
2022-05-25 03:16:44,665 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:44,703 - 

2022-05-25 03:16:44,705 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:45,304 - Epoch: [43][   10/   83]    Overall Loss 0.000005    Objective Loss 0.000005                                        LR 0.000125    Time 0.059765    
2022-05-25 03:16:45,734 - Epoch: [43][   20/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.048140    
2022-05-25 03:16:46,157 - Epoch: [43][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.044175    
2022-05-25 03:16:46,579 - Epoch: [43][   40/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000125    Time 0.042178    
2022-05-25 03:16:47,008 - Epoch: [43][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041251    
2022-05-25 03:16:47,423 - Epoch: [43][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040376    
2022-05-25 03:16:47,845 - Epoch: [43][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039791    
2022-05-25 03:16:48,270 - Epoch: [43][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039376    
2022-05-25 03:16:48,417 - Epoch: [43][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039087    
2022-05-25 03:16:48,537 - --- validate (epoch=43)-----------
2022-05-25 03:16:48,537 - 912 samples (100 per mini-batch)
2022-05-25 03:16:48,952 - Epoch: [43][   10/   10]    Loss 0.000229    Top1 100.000000    
2022-05-25 03:16:49,031 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:49,031 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:49,085 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 43]
2022-05-25 03:16:49,085 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:49,118 - 

2022-05-25 03:16:49,119 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:49,724 - Epoch: [44][   10/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.060363    
2022-05-25 03:16:50,163 - Epoch: [44][   20/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.049087    
2022-05-25 03:16:50,586 - Epoch: [44][   30/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.044764    
2022-05-25 03:16:51,006 - Epoch: [44][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.042824    
2022-05-25 03:16:51,423 - Epoch: [44][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.041620    
2022-05-25 03:16:51,849 - Epoch: [44][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040747    
2022-05-25 03:16:52,280 - Epoch: [44][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.040085    
2022-05-25 03:16:52,695 - Epoch: [44][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039616    
2022-05-25 03:16:52,835 - Epoch: [44][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039340    
2022-05-25 03:16:52,956 - --- validate (epoch=44)-----------
2022-05-25 03:16:52,957 - 912 samples (100 per mini-batch)
2022-05-25 03:16:53,372 - Epoch: [44][   10/   10]    Loss 0.000234    Top1 100.000000    
2022-05-25 03:16:53,442 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:53,442 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:53,483 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177071 on epoch: 44]
2022-05-25 03:16:53,484 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:53,514 - 

2022-05-25 03:16:53,515 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:54,121 - Epoch: [45][   10/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000125    Time 0.060442    
2022-05-25 03:16:54,553 - Epoch: [45][   20/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.048708    
2022-05-25 03:16:54,977 - Epoch: [45][   30/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000125    Time 0.044422    
2022-05-25 03:16:55,390 - Epoch: [45][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.042560    
2022-05-25 03:16:55,817 - Epoch: [45][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041571    
2022-05-25 03:16:56,235 - Epoch: [45][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040770    
2022-05-25 03:16:56,657 - Epoch: [45][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040219    
2022-05-25 03:16:57,082 - Epoch: [45][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039883    
2022-05-25 03:16:57,227 - Epoch: [45][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039580    
2022-05-25 03:16:57,348 - --- validate (epoch=45)-----------
2022-05-25 03:16:57,348 - 912 samples (100 per mini-batch)
2022-05-25 03:16:57,773 - Epoch: [45][   10/   10]    Loss 0.000219    Top1 100.000000    
2022-05-25 03:16:57,845 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:16:57,846 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:16:57,886 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 45]
2022-05-25 03:16:57,886 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:16:57,915 - 

2022-05-25 03:16:57,916 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:16:58,537 - Epoch: [46][   10/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.061952    
2022-05-25 03:16:58,962 - Epoch: [46][   20/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.049017    
2022-05-25 03:16:59,389 - Epoch: [46][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.044864    
2022-05-25 03:16:59,829 - Epoch: [46][   40/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.043206    
2022-05-25 03:17:00,259 - Epoch: [46][   50/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.041931    
2022-05-25 03:17:00,689 - Epoch: [46][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.041104    
2022-05-25 03:17:01,130 - Epoch: [46][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040750    
2022-05-25 03:17:01,552 - Epoch: [46][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040154    
2022-05-25 03:17:01,696 - Epoch: [46][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000125    Time 0.039825    
2022-05-25 03:17:01,817 - --- validate (epoch=46)-----------
2022-05-25 03:17:01,818 - 912 samples (100 per mini-batch)
2022-05-25 03:17:02,240 - Epoch: [46][   10/   10]    Loss 0.000237    Top1 100.000000    
2022-05-25 03:17:02,312 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:02,312 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:02,352 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 46]
2022-05-25 03:17:02,353 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:02,383 - 

2022-05-25 03:17:02,383 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:02,999 - Epoch: [47][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000125    Time 0.061447    
2022-05-25 03:17:03,433 - Epoch: [47][   20/   83]    Overall Loss 0.000006    Objective Loss 0.000006                                        LR 0.000125    Time 0.049503    
2022-05-25 03:17:03,866 - Epoch: [47][   30/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000125    Time 0.045615    
2022-05-25 03:17:04,289 - Epoch: [47][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.043221    
2022-05-25 03:17:04,706 - Epoch: [47][   50/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000125    Time 0.041847    
2022-05-25 03:17:05,128 - Epoch: [47][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040939    
2022-05-25 03:17:05,561 - Epoch: [47][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040539    
2022-05-25 03:17:05,967 - Epoch: [47][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.039897    
2022-05-25 03:17:06,104 - Epoch: [47][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039488    
2022-05-25 03:17:06,228 - --- validate (epoch=47)-----------
2022-05-25 03:17:06,228 - 912 samples (100 per mini-batch)
2022-05-25 03:17:06,646 - Epoch: [47][   10/   10]    Loss 0.000218    Top1 100.000000    
2022-05-25 03:17:06,715 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:06,715 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:06,756 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 47]
2022-05-25 03:17:06,757 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:06,788 - 

2022-05-25 03:17:06,789 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:07,486 - Epoch: [48][   10/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000125    Time 0.069642    
2022-05-25 03:17:07,929 - Epoch: [48][   20/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000125    Time 0.053875    
2022-05-25 03:17:08,352 - Epoch: [48][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.048166    
2022-05-25 03:17:08,786 - Epoch: [48][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.045507    
2022-05-25 03:17:09,207 - Epoch: [48][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.043602    
2022-05-25 03:17:09,621 - Epoch: [48][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.042498    
2022-05-25 03:17:10,045 - Epoch: [48][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041582    
2022-05-25 03:17:10,455 - Epoch: [48][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040867    
2022-05-25 03:17:10,606 - Epoch: [48][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000125    Time 0.040421    
2022-05-25 03:17:10,723 - --- validate (epoch=48)-----------
2022-05-25 03:17:10,724 - 912 samples (100 per mini-batch)
2022-05-25 03:17:11,148 - Epoch: [48][   10/   10]    Loss 0.000220    Top1 100.000000    
2022-05-25 03:17:11,225 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:11,225 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:11,266 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 48]
2022-05-25 03:17:11,267 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:11,302 - 

2022-05-25 03:17:11,303 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:11,911 - Epoch: [49][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.060675    
2022-05-25 03:17:12,342 - Epoch: [49][   20/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.048770    
2022-05-25 03:17:12,763 - Epoch: [49][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.044721    
2022-05-25 03:17:13,194 - Epoch: [49][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.042778    
2022-05-25 03:17:13,608 - Epoch: [49][   50/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.041472    
2022-05-25 03:17:14,036 - Epoch: [49][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040658    
2022-05-25 03:17:14,468 - Epoch: [49][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040016    
2022-05-25 03:17:14,892 - Epoch: [49][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.039521    
2022-05-25 03:17:15,032 - Epoch: [49][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000125    Time 0.039108    
2022-05-25 03:17:15,154 - --- validate (epoch=49)-----------
2022-05-25 03:17:15,154 - 912 samples (100 per mini-batch)
2022-05-25 03:17:15,584 - Epoch: [49][   10/   10]    Loss 0.000259    Top1 100.000000    
2022-05-25 03:17:15,661 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:15,661 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:15,702 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 49]
2022-05-25 03:17:15,703 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:15,734 - 

2022-05-25 03:17:15,734 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:16,354 - Epoch: [50][   10/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.061916    
2022-05-25 03:17:16,820 - Epoch: [50][   20/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000125    Time 0.049543    
2022-05-25 03:17:17,239 - Epoch: [50][   30/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000125    Time 0.045265    
2022-05-25 03:17:17,652 - Epoch: [50][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.043059    
2022-05-25 03:17:18,070 - Epoch: [50][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.041761    
2022-05-25 03:17:18,490 - Epoch: [50][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040861    
2022-05-25 03:17:18,919 - Epoch: [50][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040188    
2022-05-25 03:17:19,333 - Epoch: [50][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039680    
2022-05-25 03:17:19,477 - Epoch: [50][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039371    
2022-05-25 03:17:19,602 - --- validate (epoch=50)-----------
2022-05-25 03:17:19,602 - 912 samples (100 per mini-batch)
2022-05-25 03:17:20,028 - Epoch: [50][   10/   10]    Loss 0.000268    Top1 100.000000    
2022-05-25 03:17:20,104 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:20,104 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:20,146 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 50]
2022-05-25 03:17:20,147 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:20,181 - 

2022-05-25 03:17:20,182 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:20,796 - Epoch: [51][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000125    Time 0.061343    
2022-05-25 03:17:21,220 - Epoch: [51][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.048690    
2022-05-25 03:17:21,635 - Epoch: [51][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.044791    
2022-05-25 03:17:22,064 - Epoch: [51][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.042768    
2022-05-25 03:17:22,489 - Epoch: [51][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041479    
2022-05-25 03:17:22,902 - Epoch: [51][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040592    
2022-05-25 03:17:23,320 - Epoch: [51][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.039991    
2022-05-25 03:17:23,729 - Epoch: [51][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039507    
2022-05-25 03:17:23,868 - Epoch: [51][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000125    Time 0.039108    
2022-05-25 03:17:23,995 - --- validate (epoch=51)-----------
2022-05-25 03:17:23,995 - 912 samples (100 per mini-batch)
2022-05-25 03:17:24,422 - Epoch: [51][   10/   10]    Loss 0.000273    Top1 100.000000    
2022-05-25 03:17:24,492 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:24,493 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:24,534 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 51]
2022-05-25 03:17:24,535 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:24,569 - 

2022-05-25 03:17:24,570 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:25,177 - Epoch: [52][   10/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000125    Time 0.060602    
2022-05-25 03:17:25,597 - Epoch: [52][   20/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.048318    
2022-05-25 03:17:26,006 - Epoch: [52][   30/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.044236    
2022-05-25 03:17:26,435 - Epoch: [52][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.042331    
2022-05-25 03:17:26,852 - Epoch: [52][   50/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000125    Time 0.041175    
2022-05-25 03:17:27,263 - Epoch: [52][   60/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.040296    
2022-05-25 03:17:27,684 - Epoch: [52][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.039811    
2022-05-25 03:17:28,092 - Epoch: [52][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.039329    
2022-05-25 03:17:28,248 - Epoch: [52][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039063    
2022-05-25 03:17:28,381 - --- validate (epoch=52)-----------
2022-05-25 03:17:28,381 - 912 samples (100 per mini-batch)
2022-05-25 03:17:28,819 - Epoch: [52][   10/   10]    Loss 0.000262    Top1 100.000000    
2022-05-25 03:17:28,890 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:28,891 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:28,931 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 52]
2022-05-25 03:17:28,931 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:28,962 - 

2022-05-25 03:17:28,962 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:29,572 - Epoch: [53][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000125    Time 0.060854    
2022-05-25 03:17:29,998 - Epoch: [53][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.048554    
2022-05-25 03:17:30,423 - Epoch: [53][   30/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000125    Time 0.044843    
2022-05-25 03:17:30,849 - Epoch: [53][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.042843    
2022-05-25 03:17:31,268 - Epoch: [53][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041493    
2022-05-25 03:17:31,699 - Epoch: [53][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.040685    
2022-05-25 03:17:32,132 - Epoch: [53][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040193    
2022-05-25 03:17:32,544 - Epoch: [53][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039582    
2022-05-25 03:17:32,693 - Epoch: [53][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039292    
2022-05-25 03:17:32,816 - --- validate (epoch=53)-----------
2022-05-25 03:17:32,817 - 912 samples (100 per mini-batch)
2022-05-25 03:17:33,252 - Epoch: [53][   10/   10]    Loss 0.000226    Top1 100.000000    
2022-05-25 03:17:33,337 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:33,338 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:33,378 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 53]
2022-05-25 03:17:33,379 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:33,411 - 

2022-05-25 03:17:33,411 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:34,020 - Epoch: [54][   10/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.060651    
2022-05-25 03:17:34,453 - Epoch: [54][   20/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.048640    
2022-05-25 03:17:34,886 - Epoch: [54][   30/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000125    Time 0.044875    
2022-05-25 03:17:35,309 - Epoch: [54][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.042948    
2022-05-25 03:17:35,727 - Epoch: [54][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041672    
2022-05-25 03:17:36,149 - Epoch: [54][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040834    
2022-05-25 03:17:36,577 - Epoch: [54][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040159    
2022-05-25 03:17:36,990 - Epoch: [54][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039553    
2022-05-25 03:17:37,130 - Epoch: [54][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000125    Time 0.039279    
2022-05-25 03:17:37,260 - --- validate (epoch=54)-----------
2022-05-25 03:17:37,260 - 912 samples (100 per mini-batch)
2022-05-25 03:17:37,691 - Epoch: [54][   10/   10]    Loss 0.000283    Top1 100.000000    
2022-05-25 03:17:37,776 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:37,776 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:37,816 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 54]
2022-05-25 03:17:37,817 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:37,848 - 

2022-05-25 03:17:37,848 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:38,453 - Epoch: [55][   10/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000125    Time 0.060381    
2022-05-25 03:17:38,906 - Epoch: [55][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.049361    
2022-05-25 03:17:39,329 - Epoch: [55][   30/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.045122    
2022-05-25 03:17:39,749 - Epoch: [55][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.042900    
2022-05-25 03:17:40,176 - Epoch: [55][   50/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.041601    
2022-05-25 03:17:40,598 - Epoch: [55][   60/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.040777    
2022-05-25 03:17:41,027 - Epoch: [55][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040367    
2022-05-25 03:17:41,439 - Epoch: [55][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039852    
2022-05-25 03:17:41,584 - Epoch: [55][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039554    
2022-05-25 03:17:41,714 - --- validate (epoch=55)-----------
2022-05-25 03:17:41,715 - 912 samples (100 per mini-batch)
2022-05-25 03:17:42,148 - Epoch: [55][   10/   10]    Loss 0.000248    Top1 100.000000    
2022-05-25 03:17:42,240 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:42,240 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:42,282 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 55]
2022-05-25 03:17:42,283 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:42,313 - 

2022-05-25 03:17:42,314 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:42,936 - Epoch: [56][   10/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000125    Time 0.062067    
2022-05-25 03:17:43,354 - Epoch: [56][   20/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.048912    
2022-05-25 03:17:43,773 - Epoch: [56][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.044562    
2022-05-25 03:17:44,221 - Epoch: [56][   40/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.042968    
2022-05-25 03:17:44,636 - Epoch: [56][   50/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.041721    
2022-05-25 03:17:45,046 - Epoch: [56][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040742    
2022-05-25 03:17:45,479 - Epoch: [56][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040232    
2022-05-25 03:17:45,896 - Epoch: [56][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039834    
2022-05-25 03:17:46,040 - Epoch: [56][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039519    
2022-05-25 03:17:46,160 - --- validate (epoch=56)-----------
2022-05-25 03:17:46,160 - 912 samples (100 per mini-batch)
2022-05-25 03:17:46,583 - Epoch: [56][   10/   10]    Loss 0.000241    Top1 100.000000    
2022-05-25 03:17:46,659 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:46,659 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:46,700 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 56]
2022-05-25 03:17:46,701 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:46,732 - 

2022-05-25 03:17:46,734 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:47,347 - Epoch: [57][   10/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000125    Time 0.061148    
2022-05-25 03:17:47,783 - Epoch: [57][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.048947    
2022-05-25 03:17:48,202 - Epoch: [57][   30/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.044807    
2022-05-25 03:17:48,626 - Epoch: [57][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.042697    
2022-05-25 03:17:49,050 - Epoch: [57][   50/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000125    Time 0.041551    
2022-05-25 03:17:49,479 - Epoch: [57][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.040740    
2022-05-25 03:17:49,898 - Epoch: [57][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040133    
2022-05-25 03:17:50,309 - Epoch: [57][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039577    
2022-05-25 03:17:50,441 - Epoch: [57][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039166    
2022-05-25 03:17:50,587 - --- validate (epoch=57)-----------
2022-05-25 03:17:50,588 - 912 samples (100 per mini-batch)
2022-05-25 03:17:51,004 - Epoch: [57][   10/   10]    Loss 0.000236    Top1 100.000000    
2022-05-25 03:17:51,081 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:51,082 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:51,123 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 57]
2022-05-25 03:17:51,123 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:51,155 - 

2022-05-25 03:17:51,155 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:51,774 - Epoch: [58][   10/   83]    Overall Loss 0.000004    Objective Loss 0.000004                                        LR 0.000125    Time 0.061729    
2022-05-25 03:17:52,198 - Epoch: [58][   20/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000125    Time 0.048928    
2022-05-25 03:17:52,624 - Epoch: [58][   30/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000125    Time 0.044725    
2022-05-25 03:17:53,039 - Epoch: [58][   40/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000125    Time 0.042678    
2022-05-25 03:17:53,462 - Epoch: [58][   50/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000125    Time 0.041618    
2022-05-25 03:17:53,884 - Epoch: [58][   60/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.040852    
2022-05-25 03:17:54,311 - Epoch: [58][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040236    
2022-05-25 03:17:54,729 - Epoch: [58][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039765    
2022-05-25 03:17:54,866 - Epoch: [58][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039377    
2022-05-25 03:17:54,983 - --- validate (epoch=58)-----------
2022-05-25 03:17:54,983 - 912 samples (100 per mini-batch)
2022-05-25 03:17:55,419 - Epoch: [58][   10/   10]    Loss 0.000264    Top1 100.000000    
2022-05-25 03:17:55,496 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:55,496 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:55,538 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 58]
2022-05-25 03:17:55,538 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:17:55,568 - 

2022-05-25 03:17:55,569 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:17:56,198 - Epoch: [59][   10/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000125    Time 0.062865    
2022-05-25 03:17:56,620 - Epoch: [59][   20/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000125    Time 0.049385    
2022-05-25 03:17:57,058 - Epoch: [59][   30/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000125    Time 0.045601    
2022-05-25 03:17:57,477 - Epoch: [59][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.043296    
2022-05-25 03:17:57,896 - Epoch: [59][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041969    
2022-05-25 03:17:58,307 - Epoch: [59][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000125    Time 0.041017    
2022-05-25 03:17:58,743 - Epoch: [59][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.040457    
2022-05-25 03:17:59,166 - Epoch: [59][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000125    Time 0.039896    
2022-05-25 03:17:59,310 - Epoch: [59][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000125    Time 0.039583    
2022-05-25 03:17:59,440 - --- validate (epoch=59)-----------
2022-05-25 03:17:59,440 - 912 samples (100 per mini-batch)
2022-05-25 03:17:59,854 - Epoch: [59][   10/   10]    Loss 0.000229    Top1 100.000000    
2022-05-25 03:17:59,928 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:17:59,928 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:17:59,968 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 59]
2022-05-25 03:17:59,970 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:00,001 - 

2022-05-25 03:18:00,001 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:00,630 - Epoch: [60][   10/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000063    Time 0.062795    
2022-05-25 03:18:01,069 - Epoch: [60][   20/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000063    Time 0.050351    
2022-05-25 03:18:01,490 - Epoch: [60][   30/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000063    Time 0.045566    
2022-05-25 03:18:01,916 - Epoch: [60][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.043264    
2022-05-25 03:18:02,338 - Epoch: [60][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.041828    
2022-05-25 03:18:02,766 - Epoch: [60][   60/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.040836    
2022-05-25 03:18:03,187 - Epoch: [60][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040232    
2022-05-25 03:18:03,597 - Epoch: [60][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039687    
2022-05-25 03:18:03,732 - Epoch: [60][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000063    Time 0.039272    
2022-05-25 03:18:03,858 - --- validate (epoch=60)-----------
2022-05-25 03:18:03,858 - 912 samples (100 per mini-batch)
2022-05-25 03:18:04,281 - Epoch: [60][   10/   10]    Loss 0.000254    Top1 100.000000    
2022-05-25 03:18:04,351 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:04,351 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:04,392 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 60]
2022-05-25 03:18:04,392 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:04,420 - 

2022-05-25 03:18:04,420 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:05,025 - Epoch: [61][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.060378    
2022-05-25 03:18:05,446 - Epoch: [61][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.048138    
2022-05-25 03:18:05,860 - Epoch: [61][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.044194    
2022-05-25 03:18:06,275 - Epoch: [61][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.042195    
2022-05-25 03:18:06,689 - Epoch: [61][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.041084    
2022-05-25 03:18:07,104 - Epoch: [61][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040281    
2022-05-25 03:18:07,523 - Epoch: [61][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039723    
2022-05-25 03:18:07,936 - Epoch: [61][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039388    
2022-05-25 03:18:08,071 - Epoch: [61][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.038988    
2022-05-25 03:18:08,196 - --- validate (epoch=61)-----------
2022-05-25 03:18:08,196 - 912 samples (100 per mini-batch)
2022-05-25 03:18:08,627 - Epoch: [61][   10/   10]    Loss 0.000243    Top1 100.000000    
2022-05-25 03:18:08,710 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:08,710 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:08,751 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 61]
2022-05-25 03:18:08,753 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:08,783 - 

2022-05-25 03:18:08,784 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:09,383 - Epoch: [62][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.059701    
2022-05-25 03:18:09,809 - Epoch: [62][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.048218    
2022-05-25 03:18:10,234 - Epoch: [62][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.044236    
2022-05-25 03:18:10,659 - Epoch: [62][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.042365    
2022-05-25 03:18:11,094 - Epoch: [62][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.041385    
2022-05-25 03:18:11,517 - Epoch: [62][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.040679    
2022-05-25 03:18:11,935 - Epoch: [62][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.040063    
2022-05-25 03:18:12,370 - Epoch: [62][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039634    
2022-05-25 03:18:12,516 - Epoch: [62][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.039327    
2022-05-25 03:18:12,646 - --- validate (epoch=62)-----------
2022-05-25 03:18:12,646 - 912 samples (100 per mini-batch)
2022-05-25 03:18:13,069 - Epoch: [62][   10/   10]    Loss 0.000232    Top1 100.000000    
2022-05-25 03:18:13,143 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:13,143 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:13,183 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 62]
2022-05-25 03:18:13,185 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:13,216 - 

2022-05-25 03:18:13,217 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:13,923 - Epoch: [63][   10/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000063    Time 0.070464    
2022-05-25 03:18:14,354 - Epoch: [63][   20/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000063    Time 0.053405    
2022-05-25 03:18:14,789 - Epoch: [63][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.047961    
2022-05-25 03:18:15,210 - Epoch: [63][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.045132    
2022-05-25 03:18:15,628 - Epoch: [63][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.043454    
2022-05-25 03:18:16,046 - Epoch: [63][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.042359    
2022-05-25 03:18:16,469 - Epoch: [63][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041585    
2022-05-25 03:18:16,882 - Epoch: [63][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040898    
2022-05-25 03:18:17,022 - Epoch: [63][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.040448    
2022-05-25 03:18:17,154 - --- validate (epoch=63)-----------
2022-05-25 03:18:17,155 - 912 samples (100 per mini-batch)
2022-05-25 03:18:17,574 - Epoch: [63][   10/   10]    Loss 0.000302    Top1 100.000000    
2022-05-25 03:18:17,655 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:17,655 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:17,697 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 63]
2022-05-25 03:18:17,697 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:17,728 - 

2022-05-25 03:18:17,728 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:18,333 - Epoch: [64][   10/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000063    Time 0.060453    
2022-05-25 03:18:18,769 - Epoch: [64][   20/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.048743    
2022-05-25 03:18:19,206 - Epoch: [64][   30/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.044952    
2022-05-25 03:18:19,638 - Epoch: [64][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.043055    
2022-05-25 03:18:20,055 - Epoch: [64][   50/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.041805    
2022-05-25 03:18:20,474 - Epoch: [64][   60/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.040995    
2022-05-25 03:18:20,890 - Epoch: [64][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040337    
2022-05-25 03:18:21,303 - Epoch: [64][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039785    
2022-05-25 03:18:21,433 - Epoch: [64][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.039391    
2022-05-25 03:18:21,552 - --- validate (epoch=64)-----------
2022-05-25 03:18:21,553 - 912 samples (100 per mini-batch)
2022-05-25 03:18:21,982 - Epoch: [64][   10/   10]    Loss 0.000220    Top1 100.000000    
2022-05-25 03:18:22,060 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:22,060 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:22,101 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 64]
2022-05-25 03:18:22,102 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:22,131 - 

2022-05-25 03:18:22,132 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:22,750 - Epoch: [65][   10/   83]    Overall Loss 0.000026    Objective Loss 0.000026                                        LR 0.000063    Time 0.061672    
2022-05-25 03:18:23,185 - Epoch: [65][   20/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000063    Time 0.049329    
2022-05-25 03:18:23,612 - Epoch: [65][   30/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.045057    
2022-05-25 03:18:24,035 - Epoch: [65][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.042916    
2022-05-25 03:18:24,462 - Epoch: [65][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.041658    
2022-05-25 03:18:24,901 - Epoch: [65][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.040947    
2022-05-25 03:18:25,321 - Epoch: [65][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040267    
2022-05-25 03:18:25,739 - Epoch: [65][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039747    
2022-05-25 03:18:25,872 - Epoch: [65][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.039340    
2022-05-25 03:18:25,991 - --- validate (epoch=65)-----------
2022-05-25 03:18:25,992 - 912 samples (100 per mini-batch)
2022-05-25 03:18:26,426 - Epoch: [65][   10/   10]    Loss 0.000289    Top1 100.000000    
2022-05-25 03:18:26,501 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:26,501 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:26,541 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 65]
2022-05-25 03:18:26,543 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:26,576 - 

2022-05-25 03:18:26,577 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:27,200 - Epoch: [66][   10/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000063    Time 0.062100    
2022-05-25 03:18:27,627 - Epoch: [66][   20/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000063    Time 0.049064    
2022-05-25 03:18:28,052 - Epoch: [66][   30/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000063    Time 0.044990    
2022-05-25 03:18:28,474 - Epoch: [66][   40/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.043013    
2022-05-25 03:18:28,895 - Epoch: [66][   50/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.041823    
2022-05-25 03:18:29,306 - Epoch: [66][   60/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000063    Time 0.040810    
2022-05-25 03:18:29,729 - Epoch: [66][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.040247    
2022-05-25 03:18:30,140 - Epoch: [66][   80/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.039690    
2022-05-25 03:18:30,274 - Epoch: [66][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039275    
2022-05-25 03:18:30,394 - --- validate (epoch=66)-----------
2022-05-25 03:18:30,394 - 912 samples (100 per mini-batch)
2022-05-25 03:18:30,807 - Epoch: [66][   10/   10]    Loss 0.000250    Top1 100.000000    
2022-05-25 03:18:30,885 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:30,885 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:30,926 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 66]
2022-05-25 03:18:30,927 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:30,959 - 

2022-05-25 03:18:30,960 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:31,579 - Epoch: [67][   10/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.061734    
2022-05-25 03:18:32,009 - Epoch: [67][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.049340    
2022-05-25 03:18:32,444 - Epoch: [67][   30/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.045250    
2022-05-25 03:18:32,869 - Epoch: [67][   40/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.043015    
2022-05-25 03:18:33,290 - Epoch: [67][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.041738    
2022-05-25 03:18:33,715 - Epoch: [67][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040927    
2022-05-25 03:18:34,140 - Epoch: [67][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040405    
2022-05-25 03:18:34,548 - Epoch: [67][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039913    
2022-05-25 03:18:34,699 - Epoch: [67][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039497    
2022-05-25 03:18:34,819 - --- validate (epoch=67)-----------
2022-05-25 03:18:34,820 - 912 samples (100 per mini-batch)
2022-05-25 03:18:35,249 - Epoch: [67][   10/   10]    Loss 0.000248    Top1 100.000000    
2022-05-25 03:18:35,322 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:35,322 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:35,363 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 67]
2022-05-25 03:18:35,365 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:35,400 - 

2022-05-25 03:18:35,401 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:36,019 - Epoch: [68][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000063    Time 0.061647    
2022-05-25 03:18:36,455 - Epoch: [68][   20/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.049604    
2022-05-25 03:18:36,881 - Epoch: [68][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.045265    
2022-05-25 03:18:37,306 - Epoch: [68][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.043060    
2022-05-25 03:18:37,720 - Epoch: [68][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.041696    
2022-05-25 03:18:38,165 - Epoch: [68][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.041179    
2022-05-25 03:18:38,615 - Epoch: [68][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040794    
2022-05-25 03:18:39,034 - Epoch: [68][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.040124    
2022-05-25 03:18:39,167 - Epoch: [68][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039695    
2022-05-25 03:18:39,285 - --- validate (epoch=68)-----------
2022-05-25 03:18:39,286 - 912 samples (100 per mini-batch)
2022-05-25 03:18:39,716 - Epoch: [68][   10/   10]    Loss 0.000278    Top1 100.000000    
2022-05-25 03:18:39,787 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:39,787 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:39,827 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 68]
2022-05-25 03:18:39,829 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:39,858 - 

2022-05-25 03:18:39,859 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:40,484 - Epoch: [69][   10/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000063    Time 0.062296    
2022-05-25 03:18:40,910 - Epoch: [69][   20/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.049311    
2022-05-25 03:18:41,337 - Epoch: [69][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.045496    
2022-05-25 03:18:41,756 - Epoch: [69][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.043255    
2022-05-25 03:18:42,169 - Epoch: [69][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.042017    
2022-05-25 03:18:42,575 - Epoch: [69][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041048    
2022-05-25 03:18:43,002 - Epoch: [69][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040324    
2022-05-25 03:18:43,428 - Epoch: [69][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039854    
2022-05-25 03:18:43,565 - Epoch: [69][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039447    
2022-05-25 03:18:43,688 - --- validate (epoch=69)-----------
2022-05-25 03:18:43,688 - 912 samples (100 per mini-batch)
2022-05-25 03:18:44,110 - Epoch: [69][   10/   10]    Loss 0.000273    Top1 100.000000    
2022-05-25 03:18:44,193 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:44,194 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:44,234 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 69]
2022-05-25 03:18:44,235 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:44,264 - 

2022-05-25 03:18:44,265 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:44,890 - Epoch: [70][   10/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000063    Time 0.062203    
2022-05-25 03:18:45,311 - Epoch: [70][   20/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000063    Time 0.049155    
2022-05-25 03:18:45,734 - Epoch: [70][   30/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000063    Time 0.044844    
2022-05-25 03:18:46,146 - Epoch: [70][   40/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.042685    
2022-05-25 03:18:46,572 - Epoch: [70][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041567    
2022-05-25 03:18:46,995 - Epoch: [70][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040796    
2022-05-25 03:18:47,427 - Epoch: [70][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040307    
2022-05-25 03:18:47,851 - Epoch: [70][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039735    
2022-05-25 03:18:47,998 - Epoch: [70][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039325    
2022-05-25 03:18:48,116 - --- validate (epoch=70)-----------
2022-05-25 03:18:48,117 - 912 samples (100 per mini-batch)
2022-05-25 03:18:48,546 - Epoch: [70][   10/   10]    Loss 0.000278    Top1 100.000000    
2022-05-25 03:18:48,617 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:48,617 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:48,658 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 70]
2022-05-25 03:18:48,659 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:48,688 - 

2022-05-25 03:18:48,690 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:49,308 - Epoch: [71][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.061635    
2022-05-25 03:18:49,739 - Epoch: [71][   20/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.049069    
2022-05-25 03:18:50,168 - Epoch: [71][   30/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.045193    
2022-05-25 03:18:50,598 - Epoch: [71][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.043120    
2022-05-25 03:18:51,013 - Epoch: [71][   50/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.041721    
2022-05-25 03:18:51,438 - Epoch: [71][   60/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.040793    
2022-05-25 03:18:51,863 - Epoch: [71][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.040370    
2022-05-25 03:18:52,280 - Epoch: [71][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039862    
2022-05-25 03:18:52,422 - Epoch: [71][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039528    
2022-05-25 03:18:52,549 - --- validate (epoch=71)-----------
2022-05-25 03:18:52,549 - 912 samples (100 per mini-batch)
2022-05-25 03:18:52,982 - Epoch: [71][   10/   10]    Loss 0.000237    Top1 100.000000    
2022-05-25 03:18:53,066 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:53,067 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:53,108 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 71]
2022-05-25 03:18:53,108 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:53,140 - 

2022-05-25 03:18:53,140 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:53,748 - Epoch: [72][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.060739    
2022-05-25 03:18:54,174 - Epoch: [72][   20/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.048360    
2022-05-25 03:18:54,604 - Epoch: [72][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.044302    
2022-05-25 03:18:55,034 - Epoch: [72][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.042334    
2022-05-25 03:18:55,448 - Epoch: [72][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041160    
2022-05-25 03:18:55,879 - Epoch: [72][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040343    
2022-05-25 03:18:56,305 - Epoch: [72][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039750    
2022-05-25 03:18:56,715 - Epoch: [72][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.039214    
2022-05-25 03:18:56,864 - Epoch: [72][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.038927    
2022-05-25 03:18:56,995 - --- validate (epoch=72)-----------
2022-05-25 03:18:56,996 - 912 samples (100 per mini-batch)
2022-05-25 03:18:57,416 - Epoch: [72][   10/   10]    Loss 0.000279    Top1 100.000000    
2022-05-25 03:18:57,493 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:18:57,493 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:18:57,533 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 72]
2022-05-25 03:18:57,535 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:18:57,568 - 

2022-05-25 03:18:57,568 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:18:58,163 - Epoch: [73][   10/   83]    Overall Loss 0.000029    Objective Loss 0.000029                                        LR 0.000063    Time 0.059460    
2022-05-25 03:18:58,584 - Epoch: [73][   20/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000063    Time 0.047824    
2022-05-25 03:18:59,027 - Epoch: [73][   30/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.044332    
2022-05-25 03:18:59,454 - Epoch: [73][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.042448    
2022-05-25 03:18:59,878 - Epoch: [73][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041323    
2022-05-25 03:19:00,312 - Epoch: [73][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.040601    
2022-05-25 03:19:00,753 - Epoch: [73][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040201    
2022-05-25 03:19:01,166 - Epoch: [73][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039673    
2022-05-25 03:19:01,301 - Epoch: [73][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039255    
2022-05-25 03:19:01,422 - --- validate (epoch=73)-----------
2022-05-25 03:19:01,423 - 912 samples (100 per mini-batch)
2022-05-25 03:19:01,843 - Epoch: [73][   10/   10]    Loss 0.000361    Top1 100.000000    
2022-05-25 03:19:01,922 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:01,922 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:01,964 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 73]
2022-05-25 03:19:01,965 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:01,997 - 

2022-05-25 03:19:01,998 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:02,625 - Epoch: [74][   10/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000063    Time 0.062525    
2022-05-25 03:19:03,061 - Epoch: [74][   20/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.050001    
2022-05-25 03:19:03,487 - Epoch: [74][   30/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.045482    
2022-05-25 03:19:03,937 - Epoch: [74][   40/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.043835    
2022-05-25 03:19:04,351 - Epoch: [74][   50/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.042277    
2022-05-25 03:19:04,768 - Epoch: [74][   60/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.041359    
2022-05-25 03:19:05,186 - Epoch: [74][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.040804    
2022-05-25 03:19:05,598 - Epoch: [74][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040218    
2022-05-25 03:19:05,743 - Epoch: [74][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039884    
2022-05-25 03:19:05,867 - --- validate (epoch=74)-----------
2022-05-25 03:19:05,867 - 912 samples (100 per mini-batch)
2022-05-25 03:19:06,284 - Epoch: [74][   10/   10]    Loss 0.000271    Top1 100.000000    
2022-05-25 03:19:06,356 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:06,356 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:06,396 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 74]
2022-05-25 03:19:06,397 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:06,429 - 

2022-05-25 03:19:06,430 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:07,039 - Epoch: [75][   10/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.060796    
2022-05-25 03:19:07,476 - Epoch: [75][   20/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.049218    
2022-05-25 03:19:07,908 - Epoch: [75][   30/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.045090    
2022-05-25 03:19:08,329 - Epoch: [75][   40/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.042955    
2022-05-25 03:19:08,744 - Epoch: [75][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041751    
2022-05-25 03:19:09,174 - Epoch: [75][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.041068    
2022-05-25 03:19:09,587 - Epoch: [75][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.040382    
2022-05-25 03:19:09,997 - Epoch: [75][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039835    
2022-05-25 03:19:10,149 - Epoch: [75][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.039525    
2022-05-25 03:19:10,266 - --- validate (epoch=75)-----------
2022-05-25 03:19:10,266 - 912 samples (100 per mini-batch)
2022-05-25 03:19:10,688 - Epoch: [75][   10/   10]    Loss 0.000277    Top1 100.000000    
2022-05-25 03:19:10,762 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:10,762 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:10,803 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 75]
2022-05-25 03:19:10,804 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:10,834 - 

2022-05-25 03:19:10,835 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:11,446 - Epoch: [76][   10/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.060849    
2022-05-25 03:19:11,874 - Epoch: [76][   20/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000063    Time 0.049086    
2022-05-25 03:19:12,301 - Epoch: [76][   30/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.044934    
2022-05-25 03:19:12,721 - Epoch: [76][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.042856    
2022-05-25 03:19:13,140 - Epoch: [76][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.041637    
2022-05-25 03:19:13,552 - Epoch: [76][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.040700    
2022-05-25 03:19:13,968 - Epoch: [76][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.040081    
2022-05-25 03:19:14,390 - Epoch: [76][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039607    
2022-05-25 03:19:14,524 - Epoch: [76][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000063    Time 0.039202    
2022-05-25 03:19:14,655 - --- validate (epoch=76)-----------
2022-05-25 03:19:14,655 - 912 samples (100 per mini-batch)
2022-05-25 03:19:15,070 - Epoch: [76][   10/   10]    Loss 0.000233    Top1 100.000000    
2022-05-25 03:19:15,141 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:15,141 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:15,182 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 76]
2022-05-25 03:19:15,183 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:15,213 - 

2022-05-25 03:19:15,213 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:15,816 - Epoch: [77][   10/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.060174    
2022-05-25 03:19:16,240 - Epoch: [77][   20/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000063    Time 0.048153    
2022-05-25 03:19:16,663 - Epoch: [77][   30/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000063    Time 0.044207    
2022-05-25 03:19:17,110 - Epoch: [77][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000063    Time 0.042382    
2022-05-25 03:19:17,531 - Epoch: [77][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041155    
2022-05-25 03:19:17,958 - Epoch: [77][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.040373    
2022-05-25 03:19:18,380 - Epoch: [77][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039865    
2022-05-25 03:19:18,791 - Epoch: [77][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.039369    
2022-05-25 03:19:18,926 - Epoch: [77][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.038966    
2022-05-25 03:19:19,044 - --- validate (epoch=77)-----------
2022-05-25 03:19:19,044 - 912 samples (100 per mini-batch)
2022-05-25 03:19:19,455 - Epoch: [77][   10/   10]    Loss 0.000308    Top1 100.000000    
2022-05-25 03:19:19,536 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:19,537 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:19,577 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 77]
2022-05-25 03:19:19,578 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:19,624 - 

2022-05-25 03:19:19,624 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:20,239 - Epoch: [78][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.061422    
2022-05-25 03:19:20,681 - Epoch: [78][   20/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000063    Time 0.049637    
2022-05-25 03:19:21,104 - Epoch: [78][   30/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.045167    
2022-05-25 03:19:21,529 - Epoch: [78][   40/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000063    Time 0.042913    
2022-05-25 03:19:21,945 - Epoch: [78][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.041609    
2022-05-25 03:19:22,358 - Epoch: [78][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000063    Time 0.040744    
2022-05-25 03:19:22,786 - Epoch: [78][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.040171    
2022-05-25 03:19:23,225 - Epoch: [78][   80/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.039777    
2022-05-25 03:19:23,364 - Epoch: [78][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.039419    
2022-05-25 03:19:23,484 - --- validate (epoch=78)-----------
2022-05-25 03:19:23,484 - 912 samples (100 per mini-batch)
2022-05-25 03:19:23,908 - Epoch: [78][   10/   10]    Loss 0.000276    Top1 100.000000    
2022-05-25 03:19:23,983 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:23,983 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:24,024 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 78]
2022-05-25 03:19:24,025 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:24,056 - 

2022-05-25 03:19:24,057 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:24,764 - Epoch: [79][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000063    Time 0.070557    
2022-05-25 03:19:25,214 - Epoch: [79][   20/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000063    Time 0.054161    
2022-05-25 03:19:25,634 - Epoch: [79][   30/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000063    Time 0.048363    
2022-05-25 03:19:26,058 - Epoch: [79][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.045297    
2022-05-25 03:19:26,479 - Epoch: [79][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000063    Time 0.043507    
2022-05-25 03:19:26,935 - Epoch: [79][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.042920    
2022-05-25 03:19:27,370 - Epoch: [79][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000063    Time 0.042240    
2022-05-25 03:19:27,822 - Epoch: [79][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000063    Time 0.041826    
2022-05-25 03:19:27,959 - Epoch: [79][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000063    Time 0.041354    
2022-05-25 03:19:28,086 - --- validate (epoch=79)-----------
2022-05-25 03:19:28,087 - 912 samples (100 per mini-batch)
2022-05-25 03:19:28,523 - Epoch: [79][   10/   10]    Loss 0.000280    Top1 100.000000    
2022-05-25 03:19:28,596 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:28,597 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:28,637 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 79]
2022-05-25 03:19:28,638 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:28,667 - 

2022-05-25 03:19:28,668 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:29,353 - Epoch: [80][   10/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000031    Time 0.068336    
2022-05-25 03:19:29,830 - Epoch: [80][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.054223    
2022-05-25 03:19:30,257 - Epoch: [80][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.048294    
2022-05-25 03:19:30,684 - Epoch: [80][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.045539    
2022-05-25 03:19:31,105 - Epoch: [80][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.043884    
2022-05-25 03:19:31,544 - Epoch: [80][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042831    
2022-05-25 03:19:32,001 - Epoch: [80][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042466    
2022-05-25 03:19:32,429 - Epoch: [80][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041835    
2022-05-25 03:19:32,575 - Epoch: [80][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000031    Time 0.041464    
2022-05-25 03:19:32,692 - --- validate (epoch=80)-----------
2022-05-25 03:19:32,693 - 912 samples (100 per mini-batch)
2022-05-25 03:19:33,127 - Epoch: [80][   10/   10]    Loss 0.000298    Top1 100.000000    
2022-05-25 03:19:33,199 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:33,200 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:33,241 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 80]
2022-05-25 03:19:33,242 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:33,274 - 

2022-05-25 03:19:33,275 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:33,884 - Epoch: [81][   10/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.060789    
2022-05-25 03:19:34,338 - Epoch: [81][   20/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000031    Time 0.049585    
2022-05-25 03:19:34,769 - Epoch: [81][   30/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000031    Time 0.045395    
2022-05-25 03:19:35,196 - Epoch: [81][   40/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000031    Time 0.043137    
2022-05-25 03:19:35,644 - Epoch: [81][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.042420    
2022-05-25 03:19:36,093 - Epoch: [81][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041915    
2022-05-25 03:19:36,556 - Epoch: [81][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.041485    
2022-05-25 03:19:36,992 - Epoch: [81][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.040980    
2022-05-25 03:19:37,142 - Epoch: [81][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.040675    
2022-05-25 03:19:37,272 - --- validate (epoch=81)-----------
2022-05-25 03:19:37,272 - 912 samples (100 per mini-batch)
2022-05-25 03:19:37,695 - Epoch: [81][   10/   10]    Loss 0.000295    Top1 100.000000    
2022-05-25 03:19:37,778 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:37,779 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:37,820 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 81]
2022-05-25 03:19:37,821 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:37,857 - 

2022-05-25 03:19:37,857 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:38,566 - Epoch: [82][   10/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.070740    
2022-05-25 03:19:39,004 - Epoch: [82][   20/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000031    Time 0.054028    
2022-05-25 03:19:39,451 - Epoch: [82][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.048868    
2022-05-25 03:19:39,875 - Epoch: [82][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.045894    
2022-05-25 03:19:40,298 - Epoch: [82][   50/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.043980    
2022-05-25 03:19:40,719 - Epoch: [82][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.042809    
2022-05-25 03:19:41,136 - Epoch: [82][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041900    
2022-05-25 03:19:41,555 - Epoch: [82][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041277    
2022-05-25 03:19:41,699 - Epoch: [82][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000031    Time 0.040914    
2022-05-25 03:19:41,819 - --- validate (epoch=82)-----------
2022-05-25 03:19:41,820 - 912 samples (100 per mini-batch)
2022-05-25 03:19:42,259 - Epoch: [82][   10/   10]    Loss 0.000283    Top1 100.000000    
2022-05-25 03:19:42,335 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:42,336 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:42,379 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 82]
2022-05-25 03:19:42,379 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:42,411 - 

2022-05-25 03:19:42,411 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:43,035 - Epoch: [83][   10/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.062318    
2022-05-25 03:19:43,457 - Epoch: [83][   20/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000031    Time 0.049564    
2022-05-25 03:19:43,876 - Epoch: [83][   30/   83]    Overall Loss 0.000008    Objective Loss 0.000008                                        LR 0.000031    Time 0.045261    
2022-05-25 03:19:44,293 - Epoch: [83][   40/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.043026    
2022-05-25 03:19:44,723 - Epoch: [83][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.041974    
2022-05-25 03:19:45,147 - Epoch: [83][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041144    
2022-05-25 03:19:45,566 - Epoch: [83][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.040427    
2022-05-25 03:19:45,988 - Epoch: [83][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.039981    
2022-05-25 03:19:46,138 - Epoch: [83][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000031    Time 0.039742    
2022-05-25 03:19:46,289 - --- validate (epoch=83)-----------
2022-05-25 03:19:46,289 - 912 samples (100 per mini-batch)
2022-05-25 03:19:46,763 - Epoch: [83][   10/   10]    Loss 0.000258    Top1 100.000000    
2022-05-25 03:19:46,839 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:46,840 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:46,882 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 83]
2022-05-25 03:19:46,884 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:46,915 - 

2022-05-25 03:19:46,916 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:47,571 - Epoch: [84][   10/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.065354    
2022-05-25 03:19:48,020 - Epoch: [84][   20/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.052372    
2022-05-25 03:19:48,482 - Epoch: [84][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.047856    
2022-05-25 03:19:48,898 - Epoch: [84][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.045039    
2022-05-25 03:19:49,347 - Epoch: [84][   50/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.043894    
2022-05-25 03:19:49,789 - Epoch: [84][   60/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.043030    
2022-05-25 03:19:50,218 - Epoch: [84][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.042210    
2022-05-25 03:19:50,644 - Epoch: [84][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041615    
2022-05-25 03:19:50,791 - Epoch: [84][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.041262    
2022-05-25 03:19:50,915 - --- validate (epoch=84)-----------
2022-05-25 03:19:50,915 - 912 samples (100 per mini-batch)
2022-05-25 03:19:51,338 - Epoch: [84][   10/   10]    Loss 0.000260    Top1 100.000000    
2022-05-25 03:19:51,407 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:51,407 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:51,448 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 84]
2022-05-25 03:19:51,449 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:51,482 - 

2022-05-25 03:19:51,483 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:52,125 - Epoch: [85][   10/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.064042    
2022-05-25 03:19:52,572 - Epoch: [85][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.051065    
2022-05-25 03:19:53,038 - Epoch: [85][   30/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.047110    
2022-05-25 03:19:53,486 - Epoch: [85][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.044941    
2022-05-25 03:19:53,938 - Epoch: [85][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.043764    
2022-05-25 03:19:54,388 - Epoch: [85][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.043051    
2022-05-25 03:19:54,834 - Epoch: [85][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042541    
2022-05-25 03:19:55,257 - Epoch: [85][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041808    
2022-05-25 03:19:55,404 - Epoch: [85][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000031    Time 0.041433    
2022-05-25 03:19:55,528 - --- validate (epoch=85)-----------
2022-05-25 03:19:55,529 - 912 samples (100 per mini-batch)
2022-05-25 03:19:55,978 - Epoch: [85][   10/   10]    Loss 0.000287    Top1 100.000000    
2022-05-25 03:19:56,059 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:19:56,059 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:19:56,101 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 85]
2022-05-25 03:19:56,102 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:19:56,128 - 

2022-05-25 03:19:56,128 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:19:56,760 - Epoch: [86][   10/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000031    Time 0.063005    
2022-05-25 03:19:57,202 - Epoch: [86][   20/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000031    Time 0.050106    
2022-05-25 03:19:57,632 - Epoch: [86][   30/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.045980    
2022-05-25 03:19:58,066 - Epoch: [86][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.043934    
2022-05-25 03:19:58,500 - Epoch: [86][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042736    
2022-05-25 03:19:58,932 - Epoch: [86][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041979    
2022-05-25 03:19:59,375 - Epoch: [86][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.041571    
2022-05-25 03:19:59,812 - Epoch: [86][   80/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041071    
2022-05-25 03:19:59,947 - Epoch: [86][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000031    Time 0.040681    
2022-05-25 03:20:00,067 - --- validate (epoch=86)-----------
2022-05-25 03:20:00,067 - 912 samples (100 per mini-batch)
2022-05-25 03:20:00,513 - Epoch: [86][   10/   10]    Loss 0.000302    Top1 100.000000    
2022-05-25 03:20:00,592 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:00,593 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:00,633 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 86]
2022-05-25 03:20:00,634 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:00,665 - 

2022-05-25 03:20:00,666 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:01,298 - Epoch: [87][   10/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000031    Time 0.063061    
2022-05-25 03:20:01,736 - Epoch: [87][   20/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.050274    
2022-05-25 03:20:02,176 - Epoch: [87][   30/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000031    Time 0.046766    
2022-05-25 03:20:02,615 - Epoch: [87][   40/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.044709    
2022-05-25 03:20:03,042 - Epoch: [87][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.043328    
2022-05-25 03:20:03,493 - Epoch: [87][   60/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.042641    
2022-05-25 03:20:03,927 - Epoch: [87][   70/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.041873    
2022-05-25 03:20:04,348 - Epoch: [87][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041282    
2022-05-25 03:20:04,498 - Epoch: [87][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000031    Time 0.040934    
2022-05-25 03:20:04,642 - --- validate (epoch=87)-----------
2022-05-25 03:20:04,642 - 912 samples (100 per mini-batch)
2022-05-25 03:20:05,072 - Epoch: [87][   10/   10]    Loss 0.000299    Top1 100.000000    
2022-05-25 03:20:05,147 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:05,148 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:05,189 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 87]
2022-05-25 03:20:05,189 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:05,221 - 

2022-05-25 03:20:05,221 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:05,863 - Epoch: [88][   10/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000031    Time 0.064077    
2022-05-25 03:20:06,311 - Epoch: [88][   20/   83]    Overall Loss 0.000024    Objective Loss 0.000024                                        LR 0.000031    Time 0.050999    
2022-05-25 03:20:06,757 - Epoch: [88][   30/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000031    Time 0.046744    
2022-05-25 03:20:07,205 - Epoch: [88][   40/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000031    Time 0.044686    
2022-05-25 03:20:07,647 - Epoch: [88][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.043346    
2022-05-25 03:20:08,084 - Epoch: [88][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042377    
2022-05-25 03:20:08,525 - Epoch: [88][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041752    
2022-05-25 03:20:08,952 - Epoch: [88][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041238    
2022-05-25 03:20:09,093 - Epoch: [88][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.040814    
2022-05-25 03:20:09,220 - --- validate (epoch=88)-----------
2022-05-25 03:20:09,220 - 912 samples (100 per mini-batch)
2022-05-25 03:20:09,673 - Epoch: [88][   10/   10]    Loss 0.000306    Top1 100.000000    
2022-05-25 03:20:09,743 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:09,743 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:09,784 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 88]
2022-05-25 03:20:09,785 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:09,817 - 

2022-05-25 03:20:09,818 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:10,450 - Epoch: [89][   10/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000031    Time 0.062996    
2022-05-25 03:20:10,894 - Epoch: [89][   20/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000031    Time 0.050323    
2022-05-25 03:20:11,329 - Epoch: [89][   30/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000031    Time 0.046343    
2022-05-25 03:20:11,767 - Epoch: [89][   40/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.044300    
2022-05-25 03:20:12,206 - Epoch: [89][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.043062    
2022-05-25 03:20:12,657 - Epoch: [89][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042202    
2022-05-25 03:20:13,107 - Epoch: [89][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041696    
2022-05-25 03:20:13,540 - Epoch: [89][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041138    
2022-05-25 03:20:13,677 - Epoch: [89][   83/   83]    Overall Loss 0.000013    Objective Loss 0.000013    Top1 100.000000    LR 0.000031    Time 0.040707    
2022-05-25 03:20:13,798 - --- validate (epoch=89)-----------
2022-05-25 03:20:13,798 - 912 samples (100 per mini-batch)
2022-05-25 03:20:14,250 - Epoch: [89][   10/   10]    Loss 0.000331    Top1 100.000000    
2022-05-25 03:20:14,324 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:14,324 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:14,365 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 89]
2022-05-25 03:20:14,366 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:14,397 - 

2022-05-25 03:20:14,399 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:15,031 - Epoch: [90][   10/   83]    Overall Loss 0.000022    Objective Loss 0.000022                                        LR 0.000031    Time 0.063071    
2022-05-25 03:20:15,478 - Epoch: [90][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.050563    
2022-05-25 03:20:15,924 - Epoch: [90][   30/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.046447    
2022-05-25 03:20:16,360 - Epoch: [90][   40/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.044448    
2022-05-25 03:20:16,792 - Epoch: [90][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.043163    
2022-05-25 03:20:17,241 - Epoch: [90][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042568    
2022-05-25 03:20:17,687 - Epoch: [90][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042039    
2022-05-25 03:20:18,118 - Epoch: [90][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041441    
2022-05-25 03:20:18,270 - Epoch: [90][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.041088    
2022-05-25 03:20:18,395 - --- validate (epoch=90)-----------
2022-05-25 03:20:18,396 - 912 samples (100 per mini-batch)
2022-05-25 03:20:18,839 - Epoch: [90][   10/   10]    Loss 0.000380    Top1 100.000000    
2022-05-25 03:20:18,912 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:18,912 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:18,955 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 90]
2022-05-25 03:20:18,956 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:18,988 - 

2022-05-25 03:20:18,989 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:19,632 - Epoch: [91][   10/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000031    Time 0.064221    
2022-05-25 03:20:20,085 - Epoch: [91][   20/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.051341    
2022-05-25 03:20:20,534 - Epoch: [91][   30/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.047066    
2022-05-25 03:20:20,967 - Epoch: [91][   40/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.044653    
2022-05-25 03:20:21,409 - Epoch: [91][   50/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.043460    
2022-05-25 03:20:21,856 - Epoch: [91][   60/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042710    
2022-05-25 03:20:22,306 - Epoch: [91][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042242    
2022-05-25 03:20:22,752 - Epoch: [91][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041761    
2022-05-25 03:20:22,899 - Epoch: [91][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.041410    
2022-05-25 03:20:23,023 - --- validate (epoch=91)-----------
2022-05-25 03:20:23,023 - 912 samples (100 per mini-batch)
2022-05-25 03:20:23,455 - Epoch: [91][   10/   10]    Loss 0.000313    Top1 100.000000    
2022-05-25 03:20:23,527 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:23,527 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:23,568 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 91]
2022-05-25 03:20:23,569 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:23,600 - 

2022-05-25 03:20:23,601 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:24,229 - Epoch: [92][   10/   83]    Overall Loss 0.000037    Objective Loss 0.000037                                        LR 0.000031    Time 0.062615    
2022-05-25 03:20:24,684 - Epoch: [92][   20/   83]    Overall Loss 0.000023    Objective Loss 0.000023                                        LR 0.000031    Time 0.050990    
2022-05-25 03:20:25,115 - Epoch: [92][   30/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000031    Time 0.046703    
2022-05-25 03:20:25,555 - Epoch: [92][   40/   83]    Overall Loss 0.000019    Objective Loss 0.000019                                        LR 0.000031    Time 0.044556    
2022-05-25 03:20:25,992 - Epoch: [92][   50/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000031    Time 0.043194    
2022-05-25 03:20:26,434 - Epoch: [92][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042303    
2022-05-25 03:20:26,883 - Epoch: [92][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041921    
2022-05-25 03:20:27,299 - Epoch: [92][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041350    
2022-05-25 03:20:27,443 - Epoch: [92][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.040910    
2022-05-25 03:20:27,562 - --- validate (epoch=92)-----------
2022-05-25 03:20:27,562 - 912 samples (100 per mini-batch)
2022-05-25 03:20:28,002 - Epoch: [92][   10/   10]    Loss 0.000318    Top1 100.000000    
2022-05-25 03:20:28,078 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:28,079 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:28,121 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 92]
2022-05-25 03:20:28,121 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:28,152 - 

2022-05-25 03:20:28,153 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:28,779 - Epoch: [93][   10/   83]    Overall Loss 0.000004    Objective Loss 0.000004                                        LR 0.000031    Time 0.062462    
2022-05-25 03:20:29,240 - Epoch: [93][   20/   83]    Overall Loss 0.000004    Objective Loss 0.000004                                        LR 0.000031    Time 0.050515    
2022-05-25 03:20:29,684 - Epoch: [93][   30/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000031    Time 0.046658    
2022-05-25 03:20:30,134 - Epoch: [93][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.044752    
2022-05-25 03:20:30,572 - Epoch: [93][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.043329    
2022-05-25 03:20:31,021 - Epoch: [93][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042404    
2022-05-25 03:20:31,447 - Epoch: [93][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041655    
2022-05-25 03:20:31,880 - Epoch: [93][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.041114    
2022-05-25 03:20:32,019 - Epoch: [93][   83/   83]    Overall Loss 0.000015    Objective Loss 0.000015    Top1 100.000000    LR 0.000031    Time 0.040721    
2022-05-25 03:20:32,156 - --- validate (epoch=93)-----------
2022-05-25 03:20:32,156 - 912 samples (100 per mini-batch)
2022-05-25 03:20:32,588 - Epoch: [93][   10/   10]    Loss 0.000277    Top1 100.000000    
2022-05-25 03:20:32,660 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:32,660 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:32,701 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 93]
2022-05-25 03:20:32,702 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:32,733 - 

2022-05-25 03:20:32,735 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:33,460 - Epoch: [94][   10/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000031    Time 0.072269    
2022-05-25 03:20:33,906 - Epoch: [94][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.055251    
2022-05-25 03:20:34,342 - Epoch: [94][   30/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.049573    
2022-05-25 03:20:34,787 - Epoch: [94][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.046684    
2022-05-25 03:20:35,222 - Epoch: [94][   50/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.044805    
2022-05-25 03:20:35,672 - Epoch: [94][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.043734    
2022-05-25 03:20:36,116 - Epoch: [94][   70/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042958    
2022-05-25 03:20:36,535 - Epoch: [94][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042166    
2022-05-25 03:20:36,673 - Epoch: [94][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.041711    
2022-05-25 03:20:36,797 - --- validate (epoch=94)-----------
2022-05-25 03:20:36,797 - 912 samples (100 per mini-batch)
2022-05-25 03:20:37,228 - Epoch: [94][   10/   10]    Loss 0.000403    Top1 100.000000    
2022-05-25 03:20:37,304 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:37,304 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:37,347 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 94]
2022-05-25 03:20:37,348 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:37,378 - 

2022-05-25 03:20:37,379 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:38,000 - Epoch: [95][   10/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000031    Time 0.062043    
2022-05-25 03:20:38,441 - Epoch: [95][   20/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.050000    
2022-05-25 03:20:38,878 - Epoch: [95][   30/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.046192    
2022-05-25 03:20:39,321 - Epoch: [95][   40/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.044403    
2022-05-25 03:20:39,764 - Epoch: [95][   50/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.043202    
2022-05-25 03:20:40,217 - Epoch: [95][   60/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.042488    
2022-05-25 03:20:40,651 - Epoch: [95][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041863    
2022-05-25 03:20:41,073 - Epoch: [95][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041226    
2022-05-25 03:20:41,213 - Epoch: [95][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.040797    
2022-05-25 03:20:41,335 - --- validate (epoch=95)-----------
2022-05-25 03:20:41,335 - 912 samples (100 per mini-batch)
2022-05-25 03:20:41,766 - Epoch: [95][   10/   10]    Loss 0.000250    Top1 100.000000    
2022-05-25 03:20:41,851 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:41,851 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:41,893 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 95]
2022-05-25 03:20:41,893 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:41,927 - 

2022-05-25 03:20:41,927 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:42,578 - Epoch: [96][   10/   83]    Overall Loss 0.000006    Objective Loss 0.000006                                        LR 0.000031    Time 0.065021    
2022-05-25 03:20:43,036 - Epoch: [96][   20/   83]    Overall Loss 0.000007    Objective Loss 0.000007                                        LR 0.000031    Time 0.052382    
2022-05-25 03:20:43,480 - Epoch: [96][   30/   83]    Overall Loss 0.000010    Objective Loss 0.000010                                        LR 0.000031    Time 0.047890    
2022-05-25 03:20:43,931 - Epoch: [96][   40/   83]    Overall Loss 0.000009    Objective Loss 0.000009                                        LR 0.000031    Time 0.045740    
2022-05-25 03:20:44,367 - Epoch: [96][   50/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.044172    
2022-05-25 03:20:44,807 - Epoch: [96][   60/   83]    Overall Loss 0.000011    Objective Loss 0.000011                                        LR 0.000031    Time 0.043100    
2022-05-25 03:20:45,249 - Epoch: [96][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.042413    
2022-05-25 03:20:45,683 - Epoch: [96][   80/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.041899    
2022-05-25 03:20:45,822 - Epoch: [96][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.041436    
2022-05-25 03:20:45,928 - --- validate (epoch=96)-----------
2022-05-25 03:20:45,929 - 912 samples (100 per mini-batch)
2022-05-25 03:20:46,377 - Epoch: [96][   10/   10]    Loss 0.000298    Top1 100.000000    
2022-05-25 03:20:46,457 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:46,457 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:46,498 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 96]
2022-05-25 03:20:46,500 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:46,532 - 

2022-05-25 03:20:46,533 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:47,181 - Epoch: [97][   10/   83]    Overall Loss 0.000016    Objective Loss 0.000016                                        LR 0.000031    Time 0.064648    
2022-05-25 03:20:47,624 - Epoch: [97][   20/   83]    Overall Loss 0.000020    Objective Loss 0.000020                                        LR 0.000031    Time 0.051138    
2022-05-25 03:20:48,074 - Epoch: [97][   30/   83]    Overall Loss 0.000018    Objective Loss 0.000018                                        LR 0.000031    Time 0.046823    
2022-05-25 03:20:48,504 - Epoch: [97][   40/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000031    Time 0.044504    
2022-05-25 03:20:48,934 - Epoch: [97][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.043233    
2022-05-25 03:20:49,373 - Epoch: [97][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042500    
2022-05-25 03:20:49,839 - Epoch: [97][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.042096    
2022-05-25 03:20:50,288 - Epoch: [97][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041763    
2022-05-25 03:20:50,433 - Epoch: [97][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.041401    
2022-05-25 03:20:50,560 - --- validate (epoch=97)-----------
2022-05-25 03:20:50,560 - 912 samples (100 per mini-batch)
2022-05-25 03:20:51,004 - Epoch: [97][   10/   10]    Loss 0.000324    Top1 100.000000    
2022-05-25 03:20:51,078 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:20:51,078 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:51,119 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 97]
2022-05-25 03:20:51,121 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:51,149 - 

2022-05-25 03:20:51,150 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:51,776 - Epoch: [98][   10/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.062517    
2022-05-25 03:20:52,226 - Epoch: [98][   20/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.050171    
2022-05-25 03:20:52,663 - Epoch: [98][   30/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.046247    
2022-05-25 03:20:53,101 - Epoch: [98][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.044225    
2022-05-25 03:20:53,581 - Epoch: [98][   50/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.043241    
2022-05-25 03:20:54,008 - Epoch: [98][   60/   83]    Overall Loss 0.000015    Objective Loss 0.000015                                        LR 0.000031    Time 0.042337    
2022-05-25 03:20:54,442 - Epoch: [98][   70/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041659    
2022-05-25 03:20:54,875 - Epoch: [98][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041155    
2022-05-25 03:20:55,018 - Epoch: [98][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.040850    
2022-05-25 03:20:55,136 - --- validate (epoch=98)-----------
2022-05-25 03:20:55,137 - 912 samples (100 per mini-batch)
2022-05-25 03:20:55,569 - Epoch: [98][   10/   10]    Loss 0.000874    Top1 100.000000    
2022-05-25 03:20:55,646 - ==> Top1: 100.000    Loss: 0.001

2022-05-25 03:20:55,646 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:20:55,689 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 98]
2022-05-25 03:20:55,689 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:20:55,722 - 

2022-05-25 03:20:55,722 - Training epoch: 8211 samples (100 per mini-batch)
2022-05-25 03:20:56,373 - Epoch: [99][   10/   83]    Overall Loss 0.000012    Objective Loss 0.000012                                        LR 0.000031    Time 0.064929    
2022-05-25 03:20:56,822 - Epoch: [99][   20/   83]    Overall Loss 0.000021    Objective Loss 0.000021                                        LR 0.000031    Time 0.051742    
2022-05-25 03:20:57,256 - Epoch: [99][   30/   83]    Overall Loss 0.000017    Objective Loss 0.000017                                        LR 0.000031    Time 0.047096    
2022-05-25 03:20:57,695 - Epoch: [99][   40/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.044757    
2022-05-25 03:20:58,129 - Epoch: [99][   50/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.043320    
2022-05-25 03:20:58,581 - Epoch: [99][   60/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.042529    
2022-05-25 03:20:59,023 - Epoch: [99][   70/   83]    Overall Loss 0.000013    Objective Loss 0.000013                                        LR 0.000031    Time 0.041792    
2022-05-25 03:20:59,450 - Epoch: [99][   80/   83]    Overall Loss 0.000014    Objective Loss 0.000014                                        LR 0.000031    Time 0.041221    
2022-05-25 03:20:59,599 - Epoch: [99][   83/   83]    Overall Loss 0.000014    Objective Loss 0.000014    Top1 100.000000    LR 0.000031    Time 0.040880    
2022-05-25 03:20:59,720 - --- validate (epoch=99)-----------
2022-05-25 03:20:59,721 - 912 samples (100 per mini-batch)
2022-05-25 03:21:00,162 - Epoch: [99][   10/   10]    Loss 0.000392    Top1 100.000000    
2022-05-25 03:21:00,238 - ==> Top1: 100.000    Loss: 0.000

2022-05-25 03:21:00,239 - ==> Confusion:
[[335   0]
 [  0 577]]

2022-05-25 03:21:00,280 - ==> Best [Top1: 100.000   Sparsity:0.00   Params: 177072 on epoch: 99]
2022-05-25 03:21:00,280 - Saving checkpoint to: logs/2022.05.25-031337/qat_checkpoint.pth.tar
2022-05-25 03:21:00,311 - --- test ---------------------
2022-05-25 03:21:00,312 - 3491 samples (100 per mini-batch)
2022-05-25 03:21:03,583 - Test: [   10/   35]    Loss 1.822445    Top1 71.100000    
2022-05-25 03:21:04,957 - Test: [   20/   35]    Loss 1.798580    Top1 71.300000    
2022-05-25 03:21:07,056 - Test: [   30/   35]    Loss 1.816598    Top1 71.166667    
2022-05-25 03:21:07,782 - Test: [   35/   35]    Loss 1.783625    Top1 71.354913    
2022-05-25 03:21:07,875 - ==> Top1: 71.355    Loss: 1.784

2022-05-25 03:21:07,876 - ==> Confusion:
[[ 743 1000]
 [   0 1748]]

2022-05-25 03:21:07,877 - 
2022-05-25 03:21:07,877 - Log file for this run: /media/azra/NEON/skynet-panda/ai8x-training/logs/2022.05.25-031337/2022.05.25-031337.log
